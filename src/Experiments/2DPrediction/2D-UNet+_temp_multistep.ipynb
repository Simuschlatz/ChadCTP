{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/_distutils_hack/__init__.py:54: UserWarning: Reliance on distutils from stdlib is deprecated. Users must rely on setuptools to provide the distutils module. Avoid importing distutils or import setuptools first, and avoid setting SETUPTOOLS_USE_DISTUTILS=stdlib. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/usr/local/lib/python3.8/dist-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnbennewiz\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "/usr/local/lib/python3.8/dist-packages/kornia/feature/lightglue.py:44: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @torch.cuda.amp.custom_fwd(cast_inputs=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import os\n",
    "import random\n",
    "from typing import Any, Dict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from ipywidgets import IntSlider, interact\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from torch.nn import Parameter\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torchvision import datasets, transforms\n",
    "from torchmetrics.image import StructuralSimilarityIndexMeasure, PeakSignalNoiseRatio\n",
    "import gc\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "import wandb\n",
    "\n",
    "wandb.login()\n",
    "\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning.callbacks import RichProgressBar, ModelCheckpoint\n",
    "from pytorch_lightning.tuner import Tuner\n",
    "\n",
    "import kornia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from rich.progress import track\\nload_root=\"../QualityFiltered\"\\nsave_root=\"../NormalizedQualityFiltered\"\\nfor volume_name in track([path for path in os.listdir(root)]):\\n    #load\\n    volume_seq = np.load(os.path.join(load_root, volume_name))\\n    #min-max scaling\\n    volume_seq = (volume_seq - volume_seq.min())/(volume_seq.max() - volume_seq.min())\\n    #save\\n    np.save(os.path.join(save_root, volume_name), volume_seq)'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Small function for normalizing the already standardized data\n",
    "\"\"\"from rich.progress import track\n",
    "load_root=\"../QualityFiltered\"\n",
    "save_root=\"../NormalizedQualityFiltered\"\n",
    "for volume_name in track([path for path in os.listdir(root)]):\n",
    "    #load\n",
    "    volume_seq = np.load(os.path.join(load_root, volume_name))\n",
    "    #min-max scaling\n",
    "    volume_seq = (volume_seq - volume_seq.min())/(volume_seq.max() - volume_seq.min())\n",
    "    #save\n",
    "    np.save(os.path.join(save_root, volume_name), volume_seq)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset2D(Dataset):\n",
    "    def __init__(\n",
    "        self, data_paths, context_window=4, prediction_window=1, transform=None\n",
    "    ):\n",
    "        self.data_paths = data_paths\n",
    "        self.context_window = context_window\n",
    "        self.prediction_window = prediction_window\n",
    "        self.transform = transform\n",
    "        self.samples = []\n",
    "        self.depth = None\n",
    "        # For every path to a volume sequence in .npy\n",
    "        for data_path in self.data_paths:\n",
    "            volume_seq = np.load(data_path)\n",
    "            # remember depth, all volumes need to have the same depth\n",
    "            if self.depth == None or self.depth == volume_seq.shape[0]:\n",
    "                self.depth = volume_seq.shape[0]\n",
    "            else:\n",
    "                print(\"The depths in one or more volumes are not the same!\")\n",
    "            # Convert to tensor\n",
    "            volume_seq = torch.from_numpy(volume_seq)\n",
    "            for h in range(volume_seq.shape[1]):\n",
    "                # Generate samples\n",
    "                for t in range(\n",
    "                    len(volume_seq) - self.context_window - self.prediction_window + 1\n",
    "                ):\n",
    "                    # Input volume sequence (context_window x 1 x 256 x 256), target volume (1 x 1 x 256 x 256)\n",
    "                    self.samples.append(\n",
    "                        (\n",
    "                            volume_seq[t : t + self.context_window, h].unsqueeze(1),\n",
    "                            volume_seq[t+ self.context_window : t+ self.context_window+ self.prediction_window,h,].unsqueeze(1),\n",
    "                        )\n",
    "                    )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.samples[idx]\n",
    "\n",
    "class Dataset3D(Dataset):\n",
    "    def __init__(self, data_paths, context_window=4, prediction_window=1, transform=None):\n",
    "        self.data_paths = data_paths\n",
    "        self.context_window = context_window\n",
    "        self.prediction_window = prediction_window\n",
    "        self.transform = transform\n",
    "        self.samples = []\n",
    "        # For every path to a volume sequence in .npy\n",
    "        for data_path in self.data_paths:\n",
    "            volume_seq = np.load(data_path)\n",
    "            # Convert to tensor\n",
    "            volume_seq = torch.from_numpy(volume_seq)\n",
    "\n",
    "            for t in range(volume_seq.shape[0]-context_window-prediction_window+1):\n",
    "                self.samples.append([volume_seq[t:t+context_window].unsqueeze(1), \n",
    "                                     volume_seq[t+context_window:t+context_window+prediction_window].unsqueeze(1)])\n",
    "                # Input-shape: [T, C, D, H, W]\n",
    "                # Target-shape: [T, C, D, H, W]\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.samples[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VolumeDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, root, batch_size=4, sequence_length=4, prediction_length=1, num_workers=0, drop_last=False, pin_memory=False, train_split=0.8, val_split=0.1, test_split=0.1):\n",
    "        super().__init__()\n",
    "        self.root = root\n",
    "        self.batch_size = batch_size\n",
    "        self.sequence_length = sequence_length\n",
    "        self.prediction_length = prediction_length\n",
    "        self.num_workers = num_workers\n",
    "        self.drop_last = drop_last\n",
    "        self.pin_memory = pin_memory\n",
    "        self.train_split = train_split\n",
    "        self.val_split = val_split\n",
    "        self.test_split = test_split\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        data_paths = [os.path.join(self.root, path) for path in os.listdir(self.root)]\n",
    "        total_size = len(data_paths)\n",
    "    \n",
    "        # Normalize splits if they don’t sum to 1\n",
    "        split_sum = self.train_split + self.val_split + self.test_split\n",
    "        if split_sum != 1.0:\n",
    "            self.train_split /= split_sum\n",
    "            self.val_split /= split_sum\n",
    "            self.test_split /= split_sum\n",
    "            print(f\"Normalized splits to: train={self.train_split:.2f}, val={self.val_split:.2f}, test={self.test_split:.2f}\")\n",
    "    \n",
    "        # Compute dataset sizes\n",
    "        train_size = int(total_size * self.train_split)\n",
    "        val_size = int(total_size * self.val_split)\n",
    "        test_size = total_size - train_size - val_size  # Ensure all data is used\n",
    "    \n",
    "        # Error handling: Ensure valid split sizes\n",
    "        if train_size <= 0 or val_size <= 0 or test_size <= 0:\n",
    "            raise ValueError(f\"Invalid dataset splits: train={train_size}, val={val_size}, test={test_size}. Check your split values.\")\n",
    "    \n",
    "        # Perform random split\n",
    "        train_paths, val_paths, test_paths = random_split(data_paths, [train_size, val_size, test_size])\n",
    "    \n",
    "        self.train_dataset = Dataset2D(train_paths, self.sequence_length, self.prediction_length)\n",
    "        self.val_dataset = Dataset2D(val_paths, self.sequence_length, self.prediction_length)\n",
    "        self.test_dataset = Dataset2D(test_paths, self.sequence_length, self.prediction_length)\n",
    "    \n",
    "        self.val_dataset_3d = Dataset3D(val_paths, self.sequence_length, self.prediction_length)\n",
    "        self.test_dataset_3d = Dataset3D(test_paths, self.sequence_length, self.prediction_length)\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True, num_workers=self.num_workers, drop_last=self.drop_last, pin_memory=self.pin_memory)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return [\n",
    "            DataLoader(self.val_dataset, batch_size=self.batch_size, num_workers=self.num_workers, drop_last=self.drop_last, pin_memory=self.pin_memory),\n",
    "            DataLoader(self.val_dataset_3d, batch_size=self.batch_size, num_workers=self.num_workers, drop_last=self.drop_last, pin_memory=self.pin_memory),\n",
    "        ]\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, batch_size=self.batch_size, num_workers=self.num_workers, drop_last=self.drop_last, pin_memory=self.pin_memory)\n",
    "\n",
    "    def val_dataloader_3d(self):\n",
    "        return DataLoader(self.val_dataset_3d, batch_size=self.batch_size, num_workers=self.num_workers, drop_last=self.drop_last, pin_memory=self.pin_memory)\n",
    "    \n",
    "    def test_dataloader_3d(self):\n",
    "        return DataLoader(self.test_dataset_3d, batch_size=self.batch_size, num_workers=self.num_workers, drop_last=self.drop_last, pin_memory=self.pin_memory)\n",
    "\n",
    "    def teardown(self, stage=None):\n",
    "        if stage == \"fit\" or stage is None:\n",
    "            pass\n",
    "            #print(\"Cleaning up after training...\")\n",
    "\n",
    "        if stage == \"test\" or stage is None:\n",
    "            pass\n",
    "            #print(\"Cleaning up after testing...\")\n",
    "\n",
    "        if stage == \"validate\" or stage is None:\n",
    "            pass\n",
    "            #print(\"Cleaning up after validation...\")\n",
    "\n",
    "        # Free memory by deleting large datasets\n",
    "        del self.train_dataset\n",
    "        del self.val_dataset\n",
    "        del self.test_dataset\n",
    "        del self.val_dataset_3d\n",
    "        del self.test_dataset_3d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoubleConv2D(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, mid_channels=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if not mid_channels:\n",
    "            mid_channels = out_channels\n",
    "            \n",
    "        self.double_conv = nn.Sequential(\n",
    "            # First convolution\n",
    "            nn.Conv2d(\n",
    "                in_channels, \n",
    "                mid_channels,\n",
    "                kernel_size=3,\n",
    "                padding=1,\n",
    "                bias=False  # No bias when using batch norm\n",
    "            ),\n",
    "            nn.BatchNorm2d(mid_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            # Second convolution\n",
    "            nn.Conv2d(\n",
    "                mid_channels,\n",
    "                out_channels,\n",
    "                kernel_size=3,\n",
    "                padding=1,\n",
    "                bias=False  # No bias when using batch norm\n",
    "            ),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        # Optional: Add residual connection if input and output channels match\n",
    "        self.use_residual = in_channels == out_channels\n",
    "        \n",
    "    def forward(self, x):\n",
    "        if self.use_residual:\n",
    "            return self.double_conv(x) + x\n",
    "        return self.double_conv(x)\n",
    "    \n",
    "class TemporalBlock(nn.Module):\n",
    "    def __init__(self, channels, temporal_kernel_size=3):\n",
    "        super().__init__()\n",
    "        \n",
    "        padding = temporal_kernel_size // 2\n",
    "        \n",
    "        self.temporal_conv = nn.Sequential(\n",
    "            # Depthwise temporal conv\n",
    "            nn.Conv1d(channels, channels,\n",
    "                     kernel_size=temporal_kernel_size,\n",
    "                     padding=padding,\n",
    "                     groups=channels),\n",
    "            nn.BatchNorm1d(channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            # Point-wise conv\n",
    "            nn.Conv1d(channels, channels, kernel_size=1),\n",
    "            nn.BatchNorm1d(channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x shape: [B, C, T, H, W]\n",
    "        b, c, t, h, w = x.shape\n",
    "        \n",
    "        # Reshape for temporal convolution\n",
    "        x_temp = x.contiguous()  # Make memory contiguous\n",
    "        x_temp = x_temp.permute(0, 3, 4, 1, 2)  # [B, H, W, C, T]\n",
    "        x_temp = x_temp.reshape(b*h*w, c, t)\n",
    "        \n",
    "        # Apply temporal convolution\n",
    "        x_temp = self.temporal_conv(x_temp)\n",
    "        \n",
    "        # Reshape back\n",
    "        x_temp = x_temp.reshape(b, h, w, c, t)\n",
    "        x_temp = x_temp.permute(0, 3, 4, 1, 2)  # [B, C, T, H, W]\n",
    "        \n",
    "        return x_temp\n",
    "\n",
    "\n",
    "class UNet2DPlusTemporal(nn.Module):\n",
    "    def __init__(self, input_frames=None, base_filters=32):\n",
    "        super(UNet2DPlusTemporal, self).__init__()\n",
    "        \n",
    "        self.input_frames = input_frames\n",
    "        \n",
    "        # Encoder Path\n",
    "        self.enc1 = DoubleConv2D(1, base_filters)\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        \n",
    "        self.enc2 = DoubleConv2D(base_filters, base_filters*2)\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        \n",
    "        # Last encoder with temporal processing\n",
    "        self.enc3 = DoubleConv2D(base_filters*2, base_filters*4)\n",
    "        self.temporal_enc = TemporalBlock(\n",
    "            channels=base_filters*4,\n",
    "            temporal_kernel_size=3\n",
    "        )\n",
    "        self.pool3 = nn.MaxPool2d(2)\n",
    "        \n",
    "        # Bottleneck with temporal processing\n",
    "        self.bottleneck_spatial = DoubleConv2D(base_filters*4, base_filters*8)\n",
    "        self.temporal_bottleneck = TemporalBlock(\n",
    "            channels=base_filters*8,\n",
    "            temporal_kernel_size=3\n",
    "        )\n",
    "        \n",
    "        # Decoder Path\n",
    "        self.upconv3 = nn.ConvTranspose2d(base_filters*8, base_filters*4, \n",
    "                                         kernel_size=2, stride=2)\n",
    "        self.dec3 = DoubleConv2D(base_filters*8, base_filters*4)\n",
    "        \n",
    "        self.upconv2 = nn.ConvTranspose2d(base_filters*4, base_filters*2, \n",
    "                                         kernel_size=2, stride=2)\n",
    "        self.dec2 = DoubleConv2D(base_filters*4, base_filters*2)\n",
    "        \n",
    "        self.upconv1 = nn.ConvTranspose2d(base_filters*2, base_filters, \n",
    "                                         kernel_size=2, stride=2)\n",
    "        self.dec1 = DoubleConv2D(base_filters*2, base_filters)\n",
    "        \n",
    "        self.final_conv = nn.Conv2d(base_filters, 1, kernel_size=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x shape: [batch, time, height, width]\n",
    "        b, t, c, h, w = x.shape\n",
    "        assert t == self.input_frames, f\"Expected {self.input_frames} frames, got {t}\"\n",
    "        \n",
    "        # Process each time step through initial spatial encoders\n",
    "        encoder_features = []\n",
    "        enc3_features = []\n",
    "        \n",
    "        for i in range(t):\n",
    "            curr_frame = x[:, i]  # [B, C, H, W]\n",
    "            \n",
    "            # Initial encoder path\n",
    "            e1 = self.enc1(curr_frame)\n",
    "            p1 = self.pool1(e1)\n",
    "            \n",
    "            e2 = self.enc2(p1)\n",
    "            p2 = self.pool2(e2)\n",
    "            \n",
    "            # Store for skip connections\n",
    "            encoder_features.append((e1, e2))\n",
    "            \n",
    "            # Last encoder\n",
    "            e3 = self.enc3(p2)\n",
    "            enc3_features.append(e3)\n",
    "        \n",
    "        # Process enc3 features temporally\n",
    "        enc3_features = torch.stack(enc3_features, dim=2)  # [B, C, T, H, W]\n",
    "        enc3_processed = self.temporal_enc(enc3_features)\n",
    "        \n",
    "        # Pool spatially after temporal processing\n",
    "        b, c, t, h, w = enc3_processed.shape\n",
    "        enc3_pooled = enc3_processed.contiguous()\n",
    "        enc3_pooled = enc3_pooled.view(b*t, c, h, w)\n",
    "        enc3_pooled = self.pool3(enc3_pooled)\n",
    "        _, _, h_pooled, w_pooled = enc3_pooled.shape\n",
    "        enc3_pooled = enc3_pooled.view(b, c, t, h_pooled, w_pooled)\n",
    "        \n",
    "        # Bottleneck processing\n",
    "        bottle_features = []\n",
    "        for i in range(t):\n",
    "            curr_feat = enc3_pooled[:, :, i]  # [B, C, H, W]\n",
    "            bottle_feat = self.bottleneck_spatial(curr_feat)\n",
    "            bottle_features.append(bottle_feat)\n",
    "        \n",
    "        # Stack and apply temporal processing in bottleneck\n",
    "        bottle_features = torch.stack(bottle_features, dim=2)  # [B, C, T, H, W]\n",
    "        bottle_processed = self.temporal_bottleneck(bottle_features)\n",
    "        \n",
    "        # Take last temporal state for decoder\n",
    "        #print(f\"bottle_processed: {bottle_processed.shape}\")\n",
    "        #bottle_final = bottle_processed[:, :, -1]  # [B, C, H, W]\n",
    "        #print(f\"bottle_final: {bottle_final.shape}\")\n",
    "        \n",
    "        # Decoder path (using last frame's encoder features)\n",
    "        #e1, e2 = encoder_features[-1]\n",
    "        #e3 = enc3_processed[:, :, -1]\n",
    "        #print(enc3_processed.shape)\n",
    "        #print(e3.shape)\n",
    "\n",
    "        decoder_features = []\n",
    "        for i in range(t):\n",
    "            e1, e2 = encoder_features[i]\n",
    "            bottle_final=bottle_processed[:, :, i, :, :]\n",
    "            e3 = enc3_processed[:, :, i]\n",
    "            d3 = self.upconv3(bottle_final)\n",
    "            d3 = torch.cat([d3, e3], dim=1)\n",
    "            d3 = self.dec3(d3)\n",
    "            \n",
    "            d2 = self.upconv2(d3)\n",
    "            d2 = torch.cat([d2, e2], dim=1)\n",
    "            d2 = self.dec2(d2)\n",
    "            \n",
    "            d1 = self.upconv1(d2)\n",
    "            d1 = torch.cat([d1, e1], dim=1)\n",
    "            d1 = self.dec1(d1)\n",
    "\n",
    "            d1 = self.final_conv(d1)\n",
    "            \n",
    "            decoder_features.append(d1)\n",
    "            \n",
    "        decoder_features = torch.stack(decoder_features, dim=1)\n",
    "        #decoder_features = decoder_features.squeeze(dim=2)\n",
    "        \n",
    "        return decoder_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pl Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HuberSSIMLoss2D(nn.Module):\n",
    "    def __init__(self, alpha=0.7, delta=0.05, window_size=5, temporal_weight=0.1):\n",
    "        super().__init__()\n",
    "        # ------------------------------------------------------------------------------\n",
    "        # ALPHA (Controls balance between Huber Loss and SSIM)\n",
    "        # More alpha  → Model focuses on voxel accuracy (Huber loss)\n",
    "        # Less alpha  → Model prioritizes structural similarity (SSIM)\n",
    "        # ------------------------------------------------------------------------------\n",
    "        # Recommended tuning:\n",
    "        # - 0.6 - 0.9 → Noisy data (CT/MRI with artifacts) → More Huber\n",
    "        # - 0.4 - 0.7 → Sharp structures (CT/MRI edges)  → Balance of both\n",
    "        # - 0.3 - 0.5 → Blurry predictions → More SSIM for finer details\n",
    "        # Default: alpha = 0.7 (Strong Huber, some SSIM)\n",
    "        # ------------------------------------------------------------------------------\n",
    "        self.alpha = alpha  # More alpha = More reliance on Huber\n",
    "        # ------------------------------------------------------------------------------\n",
    "        # DELTA (Threshold where Huber Loss switches from MSE-like to MAE-like behavior)\n",
    "        # - Higher delta → More sensitive to small errors (acts like MSE)\n",
    "        # - Lower delta  → More resistant to outliers (acts like MAE)\n",
    "        # ------------------------------------------------------------------------------\n",
    "        # Recommended tuning:\n",
    "        # - > 0.05  → High-noise data (CT/MRI with artifacts) → More robust to outliers\n",
    "        # - < 0.05  → Low-noise data (Well-normalized, synthetic) → More sensitive to details\n",
    "        # - 0.02 - 0.05  → If predictions are too blurry\n",
    "        # Default: delta = 0.05 (or dynamically adjusted per epoch)\n",
    "        # ------------------------------------------------------------------------------\n",
    "        self.delta = delta  # This will be dynamically updated every epoch\n",
    "        # ------------------------------------------------------------------------------\n",
    "        # TEMPORAL WEIGHT (Penalizes abrupt voxel intensity changes between frames)\n",
    "        # - Higher value → Forces smoother transitions\n",
    "        # - Lower value  → Allows more flexibility in voxel changes\n",
    "        # ------------------------------------------------------------------------------\n",
    "        # Recommended tuning:\n",
    "        # - > 0.2  → Strong penalty for sudden intensity jumps (Flickering reduction)\n",
    "        # - 0.05 - 0.1  → Best for smoothly changing sequences (MRI, Weather, Fluids)\n",
    "        # - < 0.05  → Allows more dynamic changes (if model is too rigid)\n",
    "        # Default: temporal_weight = 0.1 (balanced smoothness)\n",
    "        # ------------------------------------------------------------------------------\n",
    "        self.temporal_weight = temporal_weight  # More weight = Stronger smoothness enforcement\n",
    "\n",
    "        #window_size means padding\n",
    "        self.ssim_module = kornia.losses.SSIMLoss(window_size=window_size, reduction=\"mean\")\n",
    "\n",
    "    def temporal_smoothness_loss(self, y_pred):\n",
    "        #Penalizes sudden changes over time by computing L1 loss between consecutive frames.\n",
    "        #So the object should remain stationary over time\n",
    "        return torch.mean(torch.abs(y_pred[:, 1:] - y_pred[:, :-1]))  # Difference between t and t+1\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        B, T, C, H, W = y_pred.shape\n",
    "\n",
    "        # Swap time and channel dimensions: [B, C*T, H, W]\n",
    "        y_pred_restructured = y_pred.permute(0, 2, 1, 3, 4).reshape(B, C * T, H, W)\n",
    "        y_true_restructured = y_true.permute(0, 2, 1, 3, 4).reshape(B, C * T, H, W)\n",
    "\n",
    "        # Computes the SSIM treating time as another spatial dimension\n",
    "        ssim_loss = self.ssim_module(y_pred_restructured, y_true_restructured)\n",
    "\n",
    "        # Computes the Huber loss with the adjusted delta\n",
    "        huber_loss = F.huber_loss(y_pred, y_true, delta=self.delta, reduction=\"mean\")\n",
    "\n",
    "        # Compute the Temporal Smoothness Loss\n",
    "        temporal_loss = self.temporal_smoothness_loss(y_pred)\n",
    "\n",
    "        # Weighted combination\n",
    "        total_loss = self.alpha * huber_loss + (1 - self.alpha) * ssim_loss + self.temporal_weight * temporal_loss\n",
    "        return total_loss, huber_loss, ssim_loss, temporal_loss\n",
    "\n",
    "class HuberSSIMLoss3D(nn.Module):\n",
    "    def __init__(self, alpha=0.7, delta=0.05, window_size=5, temporal_weight=0.1):\n",
    "        super().__init__()\n",
    "        # ------------------------------------------------------------------------------\n",
    "        # ALPHA (Controls balance between Huber Loss and SSIM)\n",
    "        # More alpha  → Model focuses on voxel accuracy (Huber loss)\n",
    "        # Less alpha  → Model prioritizes structural similarity (SSIM)\n",
    "        # ------------------------------------------------------------------------------\n",
    "        # Recommended tuning:\n",
    "        # - 0.6 - 0.9 → Noisy data (CT/MRI with artifacts) → More Huber\n",
    "        # - 0.4 - 0.7 → Sharp structures (CT/MRI edges)  → Balance of both\n",
    "        # - 0.3 - 0.5 → Blurry predictions → More SSIM for finer details\n",
    "        # Default: alpha = 0.7 (Strong Huber, some SSIM)\n",
    "        # ------------------------------------------------------------------------------\n",
    "        self.alpha = alpha  # More alpha = More reliance on Huber\n",
    "        # ------------------------------------------------------------------------------\n",
    "        # DELTA (Threshold where Huber Loss switches from MSE-like to MAE-like behavior)\n",
    "        # - Higher delta → More sensitive to small errors (acts like MSE)\n",
    "        # - Lower delta  → More resistant to outliers (acts like MAE)\n",
    "        # ------------------------------------------------------------------------------\n",
    "        # Recommended tuning:\n",
    "        # - > 0.05  → High-noise data (CT/MRI with artifacts) → More robust to outliers\n",
    "        # - < 0.05  → Low-noise data (Well-normalized, synthetic) → More sensitive to details\n",
    "        # - 0.02 - 0.05  → If predictions are too blurry\n",
    "        # Default: delta = 0.05 (or dynamically adjusted per epoch)\n",
    "        # ------------------------------------------------------------------------------\n",
    "        self.delta = delta  # This will be dynamically updated every epoch\n",
    "        # ------------------------------------------------------------------------------\n",
    "        # TEMPORAL WEIGHT (Penalizes abrupt voxel intensity changes between frames)\n",
    "        # - Higher value → Forces smoother transitions\n",
    "        # - Lower value  → Allows more flexibility in voxel changes\n",
    "        # ------------------------------------------------------------------------------\n",
    "        # Recommended tuning:\n",
    "        # - > 0.2  → Strong penalty for sudden intensity jumps (Flickering reduction)\n",
    "        # - 0.05 - 0.1  → Best for smoothly changing sequences (MRI, Weather, Fluids)\n",
    "        # - < 0.05  → Allows more dynamic changes (if model is too rigid)\n",
    "        # Default: temporal_weight = 0.1 (balanced smoothness)\n",
    "        # ------------------------------------------------------------------------------\n",
    "        self.temporal_weight = temporal_weight  # More weight = Stronger smoothness enforcement\n",
    "\n",
    "        #window_size means padding\n",
    "        self.ssim_module = kornia.losses.SSIM3DLoss(window_size=window_size, reduction=\"mean\")\n",
    "\n",
    "    def temporal_smoothness_loss(self, y_pred):\n",
    "        #Penalizes sudden changes over time by computing L1 loss between consecutive frames.\n",
    "        #So the object should remain stationary over time\n",
    "        return torch.mean(torch.abs(y_pred[:, 1:] - y_pred[:, :-1]))  # Difference between t and t+1\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        B, T, C, D, H, W = y_pred.shape\n",
    "\n",
    "        # Swap time and channel dimensions: [B, C*T, D, H, W]\n",
    "        y_pred_restructured = y_pred.permute(0, 2, 1, 3, 4, 5).reshape(B, C * T, D, H, W)\n",
    "        y_true_restructured = y_true.permute(0, 2, 1, 3, 4, 5).reshape(B, C * T, D, H, W)\n",
    "\n",
    "        # Computes the SSIM treating time as another spatial dimension\n",
    "        ssim_loss = self.ssim_module(y_pred_restructured, y_true_restructured)\n",
    "\n",
    "        # Computes the Huber loss with the adjusted delta\n",
    "        huber_loss = F.huber_loss(y_pred, y_true, delta=self.delta, reduction=\"mean\")\n",
    "\n",
    "        # Compute the Temporal Smoothness Loss\n",
    "        temporal_loss = self.temporal_smoothness_loss(y_pred)\n",
    "\n",
    "        # Weighted combination\n",
    "        total_loss = self.alpha * huber_loss + (1 - self.alpha) * ssim_loss + self.temporal_weight * temporal_loss\n",
    "        return total_loss, huber_loss, ssim_loss, temporal_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pl_Model(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        passed_model: nn.Module,\n",
    "        config: Dict[str, Any],\n",
    "    ):\n",
    "        super(Pl_Model, self).__init__()\n",
    "        self.passed_model = passed_model\n",
    "        self.config = config\n",
    "        # ------------------------------------------------------------------------------\n",
    "        # DELTA FACTOR (Scales how much delta is updated per epoch)\n",
    "        # - Higher delta_factor → More aggressive updates to delta\n",
    "        # - Lower delta_factor  → Smoother, slower changes to delta\n",
    "        # ------------------------------------------------------------------------------\n",
    "        # Recommended tuning:\n",
    "        # - > 1.5  → If delta is too unstable (jumps too much)\n",
    "        # - 1.2 - 1.5  → Best for gradual adaptation (Default)\n",
    "        # - < 1.2  → If delta changes too slowly (use for very stable datasets)\n",
    "        # ------------------------------------------------------------------------------\n",
    "        # Default: delta_factor = 1.2 (Balanced adaptation)\n",
    "        # ------------------------------------------------------------------------------\n",
    "        self.delta_factor = 1.2  # More factor = Faster delta adjustments\n",
    "        self.delta = 0.05\n",
    "        self.previous_delta = self.delta\n",
    "        \n",
    "        #speicher alle parameter ab\n",
    "        self.save_hyperparameters(ignore=[\"passed_model\"])\n",
    "\n",
    "        # Setup training components\n",
    "        self.mse_criterion = nn.MSELoss()\n",
    "        self.psnr_criterion = PeakSignalNoiseRatio()\n",
    "        self.huberssim2d_criterion = HuberSSIMLoss2D()\n",
    "        self.huberssim3d_criterion = HuberSSIMLoss3D()\n",
    "        self.huber_criterion = nn.HuberLoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.passed_model(x)\n",
    "        #Tanh has a larger gradient range, reducing saturation issues compared to sigmoid.\n",
    "        #Allows more stable gradient flow for deep networks.\n",
    "        x = 0.5*(F.tanh(x)+1)\n",
    "        return x\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        \"\"\"Sets the Optimizer for the Model\"\"\"\n",
    "        optimizer = optim.AdamW(\n",
    "            self.parameters(), \n",
    "            lr=config['learning_rate'],\n",
    "        )\n",
    "        return [optimizer]\n",
    "\n",
    "    def _calculate_loss(self, batch, mode=\"train\"):\n",
    "        \"\"\"Calculates the loss for a batch in different modes (training, validation, testing)\"\"\"\n",
    "        inputs, targets = batch\n",
    "\n",
    "        #forward pass\n",
    "        mse_loss = 0.0\n",
    "        huber_loss = 0.0\n",
    "        rmse_loss = 0.0\n",
    "        ssim_loss = 0.0\n",
    "        huberssim_loss = 0.0\n",
    "        temporal_loss = 0.0\n",
    "        psnr_loss = 0.0\n",
    "        total_loss = 0.0\n",
    "\n",
    "        #mse_loss_table = []\n",
    "        for t in range(0, self.config[\"pred_frames\"], self.config[\"pred_n_frames_per_step\"]):\n",
    "            if self.config[\"pred_frames\"]-t<self.config[\"pred_n_frames_per_step\"]:\n",
    "                frames_this_step = self.config[\"pred_frames\"]-t\n",
    "            else:\n",
    "                frames_this_step = self.config[\"pred_n_frames_per_step\"]\n",
    "            outputs = self.forward(inputs)\n",
    "            #print(f\"{t}:{t+frames_this_step}\")\n",
    "            #get only the first predicted frame\n",
    "            outputs = outputs[:, :frames_this_step, :, :]\n",
    "            \n",
    "            #calcualte losses\n",
    "            mse_loss_ = self.mse_criterion(outputs, targets[:, t:t+frames_this_step, :, :])\n",
    "            rmse_loss_ = torch.sqrt(self.mse_criterion(outputs, targets[:, t:t+frames_this_step, :, :]))\n",
    "            psnr_loss_ = self.psnr_criterion(outputs, targets[:, t:t+frames_this_step, :, :])\n",
    "            huberssim_loss_, huber_loss_, ssim_loss_, temporal_loss_ = self.huberssim2d_criterion(outputs, targets[:, t:t+frames_this_step, :, :])\n",
    "            total_loss_ = huberssim_loss_ #self.huber_criterion(outputs, targets[:, t:t+frames_this_step, :, :])  \n",
    "\n",
    "            #mse_loss_table.append([t, mse_loss_.item()])\n",
    "            \n",
    "            mse_loss += mse_loss_\n",
    "            huber_loss += huber_loss_\n",
    "            rmse_loss += rmse_loss_\n",
    "            ssim_loss += ssim_loss_\n",
    "            huberssim_loss += huberssim_loss_\n",
    "            temporal_loss += temporal_loss_\n",
    "            psnr_loss += psnr_loss_\n",
    "            total_loss += total_loss_\n",
    "            \n",
    "            inputs = torch.cat([inputs[:, self.config[\"pred_n_frames_per_step\"]:, :, :], outputs], dim=1)\n",
    "\n",
    "        #logging\n",
    "        self.log(f\"{mode}_mse_loss\", mse_loss)\n",
    "        self.log(f\"{mode}_huber_loss\", huber_loss)\n",
    "        self.log(f\"{mode}_rmse_loss\", rmse_loss)\n",
    "        self.log(f\"{mode}_ssim_loss\", ssim_loss)\n",
    "        self.log(f\"{mode}_huberssim_loss\", huberssim_loss)\n",
    "        self.log(f\"{mode}_temporal_loss\", temporal_loss)\n",
    "        self.log(f\"{mode}_psnr_loss\", psnr_loss)\n",
    "        self.log(f\"{mode}_total_loss\", total_loss, prog_bar=True)\n",
    "\n",
    "        #table logging\n",
    "        #wandb.log({\"Loss per Timestep\": wandb.plot.line(wandb.Table(data=mse_loss_table, columns=[\"Timestep\", \"Loss\"]), \"Timestep\", \"Loss\", title=\"Loss per Timestep\")})\n",
    "\n",
    "        return total_loss\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss = self._calculate_loss(batch, mode=\"train\")\n",
    "        return loss\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def validation_step(self, batch, batch_idx, dataloader_idx):\n",
    "        if dataloader_idx==1:\n",
    "            inputs, targets = batch\n",
    "            # iterate over depth\n",
    "            outputs = []\n",
    "            for d in range(inputs.shape[3]):\n",
    "                inputs_ = inputs[:, :, :, d, :, :]\n",
    "                #iterate over time\n",
    "                outputs_d = []\n",
    "                for t in range(0, inputs.shape[1], self.config[\"pred_n_frames_per_step\"]):\n",
    "                    if inputs.shape[1]-t<self.config[\"pred_n_frames_per_step\"]:\n",
    "                        frames_this_step = inputs.shape[1]-t\n",
    "                    else:\n",
    "                        frames_this_step = self.config[\"pred_n_frames_per_step\"]\n",
    "                    \n",
    "                    outputs_t = self.forward(inputs_)\n",
    "            \n",
    "                    #get only the first predicted frame\n",
    "                    outputs_t = outputs_t[:, :frames_this_step, :, :]\n",
    "            \n",
    "                    #add to depth lst\n",
    "                    outputs_d.append(outputs_t)\n",
    "            \n",
    "                    inputs_ = torch.cat([inputs_[:, self.config[\"pred_n_frames_per_step\"]:, :, :], outputs_t], dim=1)\n",
    "            \n",
    "                #concat time and add to overall lst\n",
    "                outputs_d = torch.concat(outputs_d, dim=1)\n",
    "                outputs.append(outputs_d)\n",
    "            #stack over depth\n",
    "            outputs = torch.stack(outputs, dim=3)\n",
    "\n",
    "            #calculate losses\n",
    "            mse_loss = self.mse_criterion(outputs, targets)\n",
    "            rmse_loss = torch.sqrt(self.mse_criterion(outputs, targets))\n",
    "            huberssim_loss, huber_loss, ssim_loss, temporal_loss = self.huberssim3d_criterion(outputs, targets)\n",
    "            psnr_loss = self.psnr_criterion(outputs, targets)\n",
    "            total_loss = huberssim_loss#self.huber_criterion(outputs, targets)\n",
    "\n",
    "            #logging\n",
    "            self.log(f\"overall_val_mse_loss\", mse_loss)\n",
    "            self.log(f\"overall_val_huber_loss\", huber_loss)\n",
    "            self.log(f\"overall_val_rmse_loss\", rmse_loss)\n",
    "            self.log(f\"overall_val_ssim_loss\", ssim_loss)\n",
    "            self.log(f\"overall_val_huberssim_loss\", huberssim_loss)\n",
    "            self.log(f\"overall_val_temporal_loss\", temporal_loss)\n",
    "            self.log(f\"overall_val_psnr_loss\", psnr_loss)\n",
    "            self.log(f\"overall_val_total_loss\", total_loss)\n",
    "                    \n",
    "        else:\n",
    "            _ = self._calculate_loss(batch, mode=\"val\")\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        _ = self._calculate_loss(batch, mode=\"test\")\n",
    "    \n",
    "    def on_train_epoch_end(self):\n",
    "        #adjust delta\n",
    "        val_loader = self.trainer.datamodule.val_dataloader()[0]\n",
    "        all_errors = []\n",
    "    \n",
    "        with torch.no_grad():  \n",
    "            for batch in val_loader:\n",
    "                x, y = batch\n",
    "                y_pred = self(x.to(self.device))\n",
    "                error = torch.abs(y.to(self.device) - y_pred)\n",
    "                all_errors.append(error.view(-1))\n",
    "    \n",
    "        all_errors = torch.cat(all_errors)\n",
    "        new_delta = self.delta_factor * torch.std(all_errors).item()\n",
    "\n",
    "        #Blend previous and new delta for smoother updates\n",
    "        #is capped between 0.02 and 0.35 so that is the data is too noisy huber does not just become mse\n",
    "        new_delta = min(0.5, max(0.02, 0.8 * self.previous_delta + 0.2 * new_delta))\n",
    "        self.previous_delta = new_delta\n",
    "\n",
    "        #update\n",
    "        self.huberssim2d_criterion.delta = new_delta\n",
    "        self.huberssim3d_criterion.delta = new_delta\n",
    "    \n",
    "        #logging\n",
    "        self.log(\"delta\", new_delta)\n",
    "        \n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def check_losses(self, loader, mode, use_wandb=False):\n",
    "        mse_loss = 0.0\n",
    "        huber_loss = 0.0\n",
    "        rmse_loss = 0.0\n",
    "        ssim_loss = 0.0\n",
    "        huberssim_loss = 0.0\n",
    "        temporal_loss = 0.0\n",
    "        psnr_loss = 0.0\n",
    "        total_loss = 0.0\n",
    "        for inputs, targets in loader:\n",
    "            for t in range(self.config[\"pred_frames\"]):\n",
    "                mse_loss_ = self.mse_criterion(inputs[:, -1, :, :, :].unsqueeze(1), targets[:, t, :, :].unsqueeze(1))\n",
    "                huberssim_loss_, huber_loss_, ssim_loss_, temporal_loss_ = self.huberssim2d_criterion(inputs[:, -1, :, :, :].unsqueeze(1), targets[:, t, :, :].unsqueeze(1))\n",
    "                rmse_loss_ = torch.sqrt(self.mse_criterion(inputs[:, -1, :, :, :].unsqueeze(1), targets[:, t, :, :].unsqueeze(1)))\n",
    "                psnr_loss_ = self.psnr_criterion(inputs[:, -1, :, :, :].unsqueeze(1), targets[:, t, :, :].unsqueeze(1))\n",
    "                total_loss_ = huberssim_loss_   \n",
    "                \n",
    "                mse_loss += mse_loss_.item()\n",
    "                huber_loss += huber_loss_.item()\n",
    "                rmse_loss += rmse_loss_.item()\n",
    "                ssim_loss += ssim_loss_.item()\n",
    "                huberssim_loss += huberssim_loss_.item()\n",
    "                temporal_loss += temporal_loss_.item()\n",
    "                psnr_loss += psnr_loss_.item()\n",
    "                total_loss += total_loss_.item()\n",
    "                \n",
    "        mse_loss = mse_loss / len(loader)\n",
    "        huber_loss = huber_loss / len(loader)\n",
    "        rmse_loss = rmse_loss / len(loader)\n",
    "        ssim_loss = ssim_loss / len(loader)\n",
    "        huberssim_loss = huberssim_loss / len(loader)\n",
    "        temporal_loss = temporal_loss / len(loader)\n",
    "        psnr_loss = psnr_loss / len(loader)\n",
    "        total_loss = total_loss / len(loader)\n",
    "\n",
    "        if use_wandb:\n",
    "            wandb.log({f\"Checked_{mode}_mse_loss\": mse_loss})\n",
    "            wandb.log({f\"Checked_{mode}_huber_loss\": huber_loss})\n",
    "            wandb.log({f\"Checked_{mode}_rmse_loss\": rmse_loss})\n",
    "            wandb.log({f\"Checked_{mode}_ssim_loss\": ssim_loss})\n",
    "            wandb.log({f\"Checked_{mode}_huberssim_loss\": huberssim_loss})\n",
    "            wandb.log({f\"Checked_{mode}_temporal_loss\": temporal_loss})\n",
    "            wandb.log({f\"Checked_{mode}_psnr_loss\": psnr_loss})\n",
    "            wandb.log({f\"Checked_{mode}_total_loss\": total_loss})\n",
    "        \n",
    "        return mse_loss, huber_loss, ssim_loss, huberssim_loss, temporal_loss, rmse_loss, psnr_loss, total_loss\n",
    "        \n",
    "    def log_predictions(self):\n",
    "        \"\"\"Log example predictions to wandb\"\"\"\n",
    "        #needs to be added to other method\n",
    "        if epoch % self.config['viz_interval'] == 0:\n",
    "                self.log_predictions()\n",
    "        #but this whole method needs to be rewritten\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            # Get a batch of validation data\n",
    "            data, target = next(iter(self.val_loader))\n",
    "            data = data.to(self.device)\n",
    "            target = target.to(self.device)\n",
    "            \n",
    "            # Generate predictions\n",
    "            output = self.model(data)\n",
    "            \n",
    "            # Log images\n",
    "            wandb.log({\n",
    "                \"predictions\": wandb.Image(output[0, 0].cpu()),\n",
    "                \"targets\": wandb.Image(target[0, 0].cpu()),\n",
    "                \"input_sequence\": [wandb.Image(data[0, i].cpu()) for i in range(data.shape[1])]\n",
    "            })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    \"root\": \"../NormalizedQualityFiltered\",\n",
    "    'batch_size': 2,\n",
    "    'learning_rate': 0.0001,\n",
    "    \"num_workers\": 10,#0, wenn die gpu nicht benutzt wird\n",
    "    \"pin_memory\": True if torch.cuda.is_available() else False,#False, wenn die gpu nicht benutzt wird\n",
    "    \"drop_last\": False,\n",
    "    'epochs': 40,\n",
    "    #'log_interval': 20,\n",
    "    #'viz_interval': 1,\n",
    "    'run_name': '2D-UNet+_temp',\n",
    "    'input_frames': 9,\n",
    "    \"pred_frames\": 9,\n",
    "    \"pred_n_frames_per_step\": 1,\n",
    "    'base_filters': 32,\n",
    "    \"train_split\": 0.7,\n",
    "    \"val_split\": 0.15,\n",
    "    \"test_split\": 0.15,\n",
    "}\n",
    "config[\"run_name\"] += f\"_{config['pred_frames']}\"\n",
    "if config[\"pred_frames\"] == config[\"pred_n_frames_per_step\"]:\n",
    "    config[\"run_name\"] += \"_singleshot\"\n",
    "elif config[\"pred_n_frames_per_step\"] == 1:\n",
    "    config[\"run_name\"] += \"_autoregressive\"\n",
    "else:\n",
    "    config[\"run_name\"] += f\"_multistep_{config['pred_n_frames_per_step']}\"\n",
    "\n",
    "# Get data loaders\n",
    "'''train_loader, val_loader, test_loader, val_loader_3d, test_loader_3d, train_dataset, val_dataset, test_dataset, val_dataset_3d, test_dataset_3d = get_data_loaders(\n",
    "    batch_size=config['batch_size'],\n",
    "    num_workers=config[\"num_workers\"],\n",
    "    pin_memory=config[\"pin_memory\"],\n",
    "    drop_last=config[\"drop_last\"],\n",
    "    sequence_length=config[\"input_frames\"],\n",
    "    prediction_length=config[\"pred_frames\"],\n",
    ")'''\n",
    "dm = VolumeDataModule(\n",
    "    root=config[\"root\"],\n",
    "    batch_size=config['batch_size'],\n",
    "    num_workers=config[\"num_workers\"],\n",
    "    pin_memory=config[\"pin_memory\"],\n",
    "    drop_last=config[\"drop_last\"],\n",
    "    sequence_length=config[\"input_frames\"],\n",
    "    prediction_length=config[\"pred_frames\"],\n",
    "    train_split=config[\"train_split\"],\n",
    "    val_split=config[\"val_split\"],\n",
    "    test_split=config[\"test_split\"],\n",
    ")\n",
    "\n",
    "wandb_logger = WandbLogger(entity=\"ChadCTP\", project=\"perfusion-ct-prediction\", name=config[\"run_name\"])\n",
    "\n",
    "# Initialize model for tuning\n",
    "model = UNet2DPlusTemporal(\n",
    "    input_frames=config['input_frames'],\n",
    "    base_filters=config['base_filters'],\n",
    ")\n",
    "\n",
    "# Initialize pl_model for tuning\n",
    "pl_model = Pl_Model(\n",
    "    passed_model=model,\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor=\"val_total_loss/dataloader_idx_0\",  \n",
    "    mode=\"min\",  \n",
    "    save_top_k=1,  \n",
    "    filename=\"best-checkpoint\",\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "# Initialize trainer for tuning\n",
    "trainer = pl.Trainer(\n",
    "    logger=wandb_logger,\n",
    "    accelerator=\"gpu\",\n",
    "    devices= [1] if torch.cuda.is_available() else None,\n",
    "    max_epochs=config[\"epochs\"],\n",
    "    callbacks=[RichProgressBar(), checkpoint_callback],\n",
    "    check_val_every_n_epoch=5,\n",
    ")\n",
    "\n",
    "#wandb_logger.watch(pl_model, log_graph=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>./wandb/run-20250218_083053-z2h7q35o</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ChadCTP/perfusion-ct-prediction/runs/z2h7q35o' target=\"_blank\">2D-UNet+_temp_9_autoregressive</a></strong> to <a href='https://wandb.ai/ChadCTP/perfusion-ct-prediction' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ChadCTP/perfusion-ct-prediction' target=\"_blank\">https://wandb.ai/ChadCTP/perfusion-ct-prediction</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ChadCTP/perfusion-ct-prediction/runs/z2h7q35o' target=\"_blank\">https://wandb.ai/ChadCTP/perfusion-ct-prediction/runs/z2h7q35o</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name                  </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type                 </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ passed_model          │ UNet2DPlusTemporal   │  2.0 M │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ mse_criterion         │ MSELoss              │      0 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ psnr_criterion        │ PeakSignalNoiseRatio │      0 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ huberssim2d_criterion │ HuberSSIMLoss2D      │      0 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4 </span>│ huberssim3d_criterion │ HuberSSIMLoss3D      │      0 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 5 </span>│ huber_criterion       │ HuberLoss            │      0 │ train │\n",
       "└───┴───────────────────────┴──────────────────────┴────────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName                 \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType                \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ passed_model          │ UNet2DPlusTemporal   │  2.0 M │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ mse_criterion         │ MSELoss              │      0 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ psnr_criterion        │ PeakSignalNoiseRatio │      0 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ huberssim2d_criterion │ HuberSSIMLoss2D      │      0 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m4\u001b[0m\u001b[2m \u001b[0m│ huberssim3d_criterion │ HuberSSIMLoss3D      │      0 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m5\u001b[0m\u001b[2m \u001b[0m│ huber_criterion       │ HuberLoss            │      0 │ train │\n",
       "└───┴───────────────────────┴──────────────────────┴────────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 2.0 M                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 2.0 M                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 8                                                                          \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 2.0 M                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 2.0 M                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 8                                                                          \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fff7776a43e64c05b9e972c590e031fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 3320: 'val_total_loss/dataloader_idx_0' reached inf (best inf), saving model to './perfusion-ct-prediction/z2h7q35o/checkpoints/best-checkpoint.ckpt' as top 1\n",
      "Epoch 9, global step 6640: 'val_total_loss/dataloader_idx_0' was not in top 1\n",
      "Epoch 14, global step 9960: 'val_total_loss/dataloader_idx_0' was not in top 1\n",
      "Epoch 19, global step 13280: 'val_total_loss/dataloader_idx_0' was not in top 1\n",
      "Epoch 24, global step 16600: 'val_total_loss/dataloader_idx_0' was not in top 1\n",
      "Epoch 29, global step 19920: 'val_total_loss/dataloader_idx_0' was not in top 1\n",
      "Epoch 34, global step 23240: 'val_total_loss/dataloader_idx_0' was not in top 1\n",
      "Epoch 39, global step 26560: 'val_total_loss/dataloader_idx_0' was not in top 1\n",
      "`Trainer.fit` stopped: `max_epochs=40` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.fit(\n",
    "    model=pl_model,\n",
    "    datamodule=dm,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.004597377111765941,\n",
       " 0.0007119470029513314,\n",
       " 0.2184683965843808,\n",
       " nan,\n",
       " nan,\n",
       " 0.18980021516204273,\n",
       " 297.7571638508847,\n",
       " nan)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check and log the losses \"to beat\"\n",
    "dm.setup()\n",
    "pl_model.check_losses(dm.train_dataloader(), mode=\"train\", use_wandb=True)\n",
    "pl_model.check_losses(dm.val_dataloader()[0], mode=\"val\", use_wandb=True)\n",
    "pl_model.check_losses(dm.test_dataloader(), mode=\"test\", use_wandb=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f0fc6aa49fd443bb91f90156d2fc92a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric       </span>┃<span style=\"font-weight: bold\">        DataLoader 0        </span>┃<span style=\"font-weight: bold\">        DataLoader 1        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">   overall_val_huber_loss   </span>│<span style=\"color: #800080; text-decoration-color: #800080\">                            </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   5.5193770094774663e-05   </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> overall_val_huberssim_loss </span>│<span style=\"color: #800080; text-decoration-color: #800080\">                            </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.011345108039677143    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">    overall_val_mse_loss    </span>│<span style=\"color: #800080; text-decoration-color: #800080\">                            </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.00031943153589963913   </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">   overall_val_psnr_loss    </span>│<span style=\"color: #800080; text-decoration-color: #800080\">                            </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     35.272796630859375     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">   overall_val_rmse_loss    </span>│<span style=\"color: #800080; text-decoration-color: #800080\">                            </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.017555508762598038    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">   overall_val_ssim_loss    </span>│<span style=\"color: #800080; text-decoration-color: #800080\">                            </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.03717964142560959     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> overall_val_temporal_loss  </span>│<span style=\"color: #800080; text-decoration-color: #800080\">                            </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.0015258090570569038    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">   overall_val_total_loss   </span>│<span style=\"color: #800080; text-decoration-color: #800080\">                            </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.011345108039677143    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       val_huber_loss       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.0004967429558746517    </span>│<span style=\"color: #800080; text-decoration-color: #800080\">                            </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     val_huberssim_loss     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">            nan             </span>│<span style=\"color: #800080; text-decoration-color: #800080\">                            </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        val_mse_loss        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.0028748787008225918    </span>│<span style=\"color: #800080; text-decoration-color: #800080\">                            </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       val_psnr_loss        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     320.1243591308594      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">                            </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       val_rmse_loss        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.1487736999988556     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">                            </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       val_ssim_loss        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.16209197044372559     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">                            </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     val_temporal_loss      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">            nan             </span>│<span style=\"color: #800080; text-decoration-color: #800080\">                            </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       val_total_loss       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">            nan             </span>│<span style=\"color: #800080; text-decoration-color: #800080\">                            </span>│\n",
       "└────────────────────────────┴────────────────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       DataLoader 1       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m  overall_val_huber_loss  \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m                          \u001b[0m\u001b[35m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  5.5193770094774663e-05  \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36moverall_val_huberssim_loss\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m                          \u001b[0m\u001b[35m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.011345108039677143   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m   overall_val_mse_loss   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m                          \u001b[0m\u001b[35m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.00031943153589963913  \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m  overall_val_psnr_loss   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m                          \u001b[0m\u001b[35m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    35.272796630859375    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m  overall_val_rmse_loss   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m                          \u001b[0m\u001b[35m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.017555508762598038   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m  overall_val_ssim_loss   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m                          \u001b[0m\u001b[35m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.03717964142560959    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36moverall_val_temporal_loss \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m                          \u001b[0m\u001b[35m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.0015258090570569038   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m  overall_val_total_loss  \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m                          \u001b[0m\u001b[35m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.011345108039677143   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      val_huber_loss      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.0004967429558746517   \u001b[0m\u001b[35m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m                          \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    val_huberssim_loss    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           nan            \u001b[0m\u001b[35m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m                          \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       val_mse_loss       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.0028748787008225918   \u001b[0m\u001b[35m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m                          \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      val_psnr_loss       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    320.1243591308594     \u001b[0m\u001b[35m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m                          \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      val_rmse_loss       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.1487736999988556    \u001b[0m\u001b[35m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m                          \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      val_ssim_loss       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.16209197044372559    \u001b[0m\u001b[35m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m                          \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    val_temporal_loss     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           nan            \u001b[0m\u001b[35m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m                          \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      val_total_loss      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           nan            \u001b[0m\u001b[35m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m                          \u001b[0m\u001b[35m \u001b[0m│\n",
       "└────────────────────────────┴────────────────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_results = trainer.validate(pl_model, datamodule=dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36eec130039f42ad81e70aac8157b1a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test_huber_loss      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">  0.00045256895828060806   </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">    test_huberssim_loss    </span>│<span style=\"color: #800080; text-decoration-color: #800080\">            nan            </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       test_mse_loss       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.0027253027074038982   </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test_psnr_loss       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    321.79241943359375     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test_rmse_loss       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.1415521651506424     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test_ssim_loss       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.14753317832946777    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">    test_temporal_loss     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">            nan            </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test_total_loss      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">            nan            </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test_huber_loss     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m 0.00045256895828060806  \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m   test_huberssim_loss   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           nan           \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      test_mse_loss      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.0027253027074038982  \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test_psnr_loss      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   321.79241943359375    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test_rmse_loss      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.1415521651506424    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test_ssim_loss      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.14753317832946777   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m   test_temporal_loss    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           nan           \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test_total_loss     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           nan           \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_results = trainer.test(pl_model, datamodule=dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_load_path = f\"../ModelWeights/{config['run_name']}.ckpt\"\n",
    "trainer.save_checkpoint(save_load_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.00020112004203838297,\n",
       " 0.00010056002101919149,\n",
       " 0.01394939050078392,\n",
       " 37.25218620300293,\n",
       " 0.0006227553025382804)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@torch.no_grad()\n",
    "def overall_loss(model, loader, device):\n",
    "    mse_loss = 0.0\n",
    "    huber_loss = 0.0\n",
    "    rmse_loss = 0.0\n",
    "    #ssim_loss = 0.0\n",
    "    psnr_loss = 0.0\n",
    "    total_loss = 0.0\n",
    "    model = model.to(device)\n",
    "    for inputs, targets in loader:\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "        # iterate over depth\n",
    "        outputs = []\n",
    "        for d in range(inputs.shape[3]):\n",
    "            inputs_ = inputs[:, :, :, d, :, :]\n",
    "            #iterate over time\n",
    "            outputs_d = []\n",
    "            for t in range(0, model.config[\"pred_frames\"], model.config[\"pred_n_frames_per_step\"]):\n",
    "                if model.config[\"pred_frames\"]-t<model.config[\"pred_n_frames_per_step\"]:\n",
    "                    frames_this_step = model.config[\"pred_frames\"]-t\n",
    "                else:\n",
    "                    frames_this_step = model.config[\"pred_n_frames_per_step\"]\n",
    "                \n",
    "                outputs_t = model.forward(inputs_)\n",
    "        \n",
    "                #get only the first predicted frame\n",
    "                outputs_t = outputs_t[:, :frames_this_step, :, :]\n",
    "\n",
    "                #add to depth lst\n",
    "                outputs_d.append(outputs_t)\n",
    "        \n",
    "                inputs_ = torch.cat([inputs_[:, model.config[\"pred_n_frames_per_step\"]:, :, :], outputs_t], dim=1)\n",
    "            #concat time and add to overall lst\n",
    "            outputs_d = torch.concat(outputs_d, dim=1)\n",
    "            outputs.append(outputs_d)\n",
    "    \n",
    "        #stack over depth\n",
    "        outputs = torch.stack(outputs, dim=3)\n",
    "        #print(outputs.shape)\n",
    "        \n",
    "        #calculate losses\n",
    "        mse_loss += model.mse_criterion(outputs, targets).item()\n",
    "        huber_loss += model.huber_criterion(outputs, targets).item()\n",
    "        rmse_loss += torch.sqrt(model.mse_criterion(outputs, targets)).item()\n",
    "        #ssim_loss = model.ssim_criterion(outputs, targets).item()\n",
    "        psnr_loss += model.psnr_criterion(outputs, targets).item()\n",
    "        total_loss += huber_loss\n",
    "\n",
    "    mse_loss = mse_loss / len(loader)\n",
    "    huber_loss = huber_loss / len(loader)\n",
    "    rmse_loss = rmse_loss / len(loader)\n",
    "    #ssim_loss = ssim_loss / len(loader)\n",
    "    psnr_loss = psnr_loss / len(loader)\n",
    "    total_loss = total_loss / len(loader)\n",
    "\n",
    "    return outputs, mse_loss, huber_loss, rmse_loss, psnr_loss, total_loss\n",
    "\n",
    "dm.setup()\n",
    "_, mse_loss, huber_loss, rmse_loss, psnr_loss, total_loss = overall_loss(model=pl_model, loader=dm.test_dataloader_3d(), device=device)\n",
    "mse_loss, huber_loss, rmse_loss, psnr_loss, total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# idk tuning behaves really weird and different from fit regarding memory usage\\n#tuning\\ntuner = Tuner(trainer)\\ntuner.scale_batch_size(pl_model, datamodule=dm, mode=\"binsearch\")\\n\\n#cleaning up\\ndel tuner\\ndel trainer\\ndel pl_model\\ndel model\\ngc.collect()\\ntorch.cuda.empty_cache()\\nif torch.cuda.is_available():\\n    torch.cuda.ipc_collect()\\n\\n# Reinitialize model for tuning\\nmodel = SimVP(\\n    shape_in=[config[\"input_frames\"], 1, 256, 256]\\n)\\n\\n# Reinitialize pl_model for training\\npl_model = Pl_Model(\\n    passed_model=model,\\n    config=config,\\n)\\n\\n# Reinitialize trainer for training\\ntrainer = pl.Trainer(\\n    logger=wandb_logger,\\n    accelerator=\"gpu\",\\n    devices= [2] if torch.cuda.is_available() else None,\\n    max_epochs=config[\"epochs\"],\\n    callbacks=[RichProgressBar()],\\n    check_val_every_n_epoch=1,\\n    #enable_checkpointing=False,\\n)'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# idk tuning behaves really weird and different from fit regarding memory usage\n",
    "#tuning\n",
    "tuner = Tuner(trainer)\n",
    "tuner.scale_batch_size(pl_model, datamodule=dm, mode=\"binsearch\")\n",
    "\n",
    "#cleaning up\n",
    "del tuner\n",
    "del trainer\n",
    "del pl_model\n",
    "del model\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.ipc_collect()\n",
    "\n",
    "# Reinitialize model for tuning\n",
    "model = SimVP(\n",
    "    shape_in=[config[\"input_frames\"], 1, 256, 256]\n",
    ")\n",
    "\n",
    "# Reinitialize pl_model for training\n",
    "pl_model = Pl_Model(\n",
    "    passed_model=model,\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "# Reinitialize trainer for training\n",
    "trainer = pl.Trainer(\n",
    "    logger=wandb_logger,\n",
    "    accelerator=\"gpu\",\n",
    "    devices= [2] if torch.cuda.is_available() else None,\n",
    "    max_epochs=config[\"epochs\"],\n",
    "    callbacks=[RichProgressBar()],\n",
    "    check_val_every_n_epoch=1,\n",
    "    #enable_checkpointing=False,\n",
    ")'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
