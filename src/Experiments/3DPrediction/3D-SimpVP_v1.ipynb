{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/_distutils_hack/__init__.py:54: UserWarning: Reliance on distutils from stdlib is deprecated. Users must rely on setuptools to provide the distutils module. Avoid importing distutils or import setuptools first, and avoid setting SETUPTOOLS_USE_DISTUTILS=stdlib. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnbennewiz\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import random\n",
    "import pytorch_lightning as pl\n",
    "from torch.nn import Parameter\n",
    "from typing import Dict, Any\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import IntSlider, interact\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "import wandb\n",
    "wandb.login()\n",
    "\n",
    "from pytorch_lightning.loggers import WandbLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset3D(Dataset):\n",
    "    def __init__(self, data_paths, context_window=4, prediction_window=1, transform=None):\n",
    "        self.data_paths = data_paths\n",
    "        self.context_window = context_window\n",
    "        self.prediction_window = prediction_window\n",
    "        self.transform = transform\n",
    "        self.samples = []\n",
    "        # For every path to a volume sequence in .npy\n",
    "        for data_path in self.data_paths:\n",
    "            volume_seq = np.load(data_path)\n",
    "            # Convert to tensor\n",
    "            volume_seq = torch.from_numpy(volume_seq)\n",
    "\n",
    "            for t in range(volume_seq.shape[0]-context_window-prediction_window+1):\n",
    "                self.samples.append([volume_seq[t:t+context_window].unsqueeze(1), volume_seq[t+context_window:t+context_window+prediction_window].unsqueeze(1)])\n",
    "                # Input-shape: [T, C, D, H, W]\n",
    "                # Target-shape: [T, C, D, H, W]\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.samples[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "root = '../Data'\n",
    "# Training parameters\n",
    "batch_size = 4\n",
    "sequence_length = 8\n",
    "prediction_length=1\n",
    "learning_rate = 1e-4\n",
    "num_epochs = 100\n",
    "# Data parameters\n",
    "train_split = 0.8\n",
    "val_split = 0.1\n",
    "\n",
    "\n",
    "data_paths = [os.path.join(root, path) for path in os.listdir(root)]\n",
    "dataset = Dataset3D(data_paths, context_window=4)\n",
    "print(len(data_paths))\n",
    "def get_data_loaders(batch_size=4, sequence_length=4, prediction_length=1, num_workers=0, pin_memory=False, drop_last=False):\n",
    "    # Load all folder paths\n",
    "    # Split into train/val/test\n",
    "    n_train = int(len(data_paths) * train_split)\n",
    "    n_val = int(len(data_paths) * val_split)\n",
    "    train_paths = data_paths[:n_train]\n",
    "    val_paths = data_paths[n_train:n_train+n_val]\n",
    "    test_paths = data_paths[n_train+n_val:]\n",
    "    \n",
    "    # Create datasets\n",
    "    train_dataset = Dataset3D(train_paths, sequence_length, prediction_length)\n",
    "    val_dataset = Dataset3D(val_paths, sequence_length, prediction_length)\n",
    "    test_dataset = Dataset3D(test_paths, sequence_length, prediction_length)\n",
    "    \n",
    "    # Create dataloaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=drop_last)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, drop_last=drop_last)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, drop_last=drop_last)\n",
    "    \n",
    "    return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_loader, val_loader, test_loader = get_data_loaders(\n",
    "    batch_size=batch_size, \n",
    "    sequence_length=sequence_length, \n",
    "    prediction_length=prediction_length,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 torch.Size([4, 8, 1, 16, 256, 256]) torch.Size([4, 1, 1, 16, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "for i, (input, target) in enumerate(train_loader):\n",
    "    print(i, input.shape, target.shape)#[N, T, C, D, H, W]\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3D SimVP Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicConv3d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, transpose=False, act_norm=False):\n",
    "        super(BasicConv3d, self).__init__()\n",
    "        self.act_norm=act_norm\n",
    "        if not transpose:\n",
    "            self.conv = nn.Conv3d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding)\n",
    "        else:\n",
    "            self.conv = nn.ConvTranspose3d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding,output_padding=stride //2 )\n",
    "        self.norm = nn.GroupNorm(2, out_channels)\n",
    "        self.act = nn.LeakyReLU(0.2, inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.conv(x)\n",
    "        if self.act_norm:\n",
    "            y = self.act(self.norm(y))\n",
    "        return y\n",
    "\n",
    "\n",
    "class ConvSC(nn.Module):\n",
    "    def __init__(self, C_in, C_out, stride, transpose=False, act_norm=True):\n",
    "        super(ConvSC, self).__init__()\n",
    "        if stride == 1:\n",
    "            transpose = False\n",
    "        self.conv = BasicConv3d(C_in, C_out, kernel_size=3, stride=stride,\n",
    "                                padding=1, transpose=transpose, act_norm=act_norm)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.conv(x)\n",
    "        return y\n",
    "\n",
    "\n",
    "class GroupConv3d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, groups, act_norm=False):\n",
    "        super(GroupConv3d, self).__init__()\n",
    "        self.act_norm = act_norm\n",
    "        if in_channels % groups != 0:\n",
    "            groups = 1\n",
    "        self.conv = nn.Conv3d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding,groups=groups)\n",
    "        self.norm = nn.GroupNorm(groups,out_channels)\n",
    "        self.activate = nn.LeakyReLU(0.2, inplace=True)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        y = self.conv(x)\n",
    "        if self.act_norm:\n",
    "            y = self.activate(self.norm(y))\n",
    "        return y\n",
    "\n",
    "\n",
    "class Inception(nn.Module):\n",
    "    def __init__(self, C_in, C_hid, C_out, incep_ker=[3,5,7,11], groups=8):        \n",
    "        super(Inception, self).__init__()\n",
    "        self.conv1 = nn.Conv3d(C_in, C_hid, kernel_size=1, stride=1, padding=0)\n",
    "        layers = []\n",
    "        for ker in incep_ker:\n",
    "            layers.append(GroupConv3d(C_hid, C_out, kernel_size=ker, stride=1, padding=ker//2, groups=groups, act_norm=True))\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        y = 0\n",
    "        for layer in self.layers:\n",
    "            y += layer(x)\n",
    "        return y\n",
    "\n",
    "def stride_generator(N, reverse=False):\n",
    "    strides = [1, 2]*10\n",
    "    if reverse: return list(reversed(strides[:N]))\n",
    "    else: return strides[:N]\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self,C_in, C_hid, N_S):\n",
    "        super(Encoder,self).__init__()\n",
    "        strides = stride_generator(N_S)\n",
    "        self.enc = nn.Sequential(\n",
    "            ConvSC(C_in, C_hid, stride=strides[0]),\n",
    "            *[ConvSC(C_hid, C_hid, stride=s) for s in strides[1:]]\n",
    "        )\n",
    "    \n",
    "    def forward(self,x):# B*4, 3, 128, 128\n",
    "        enc1 = self.enc[0](x)\n",
    "        latent = enc1\n",
    "        for i in range(1,len(self.enc)):\n",
    "            latent = self.enc[i](latent)\n",
    "        return latent,enc1\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self,C_hid, C_out, N_S):\n",
    "        super(Decoder,self).__init__()\n",
    "        strides = stride_generator(N_S, reverse=True)\n",
    "        self.dec = nn.Sequential(\n",
    "            *[ConvSC(C_hid, C_hid, stride=s, transpose=True) for s in strides[:-1]],\n",
    "            ConvSC(2*C_hid, C_hid, stride=strides[-1], transpose=True)\n",
    "        )\n",
    "        self.readout = nn.Conv3d(C_hid, C_out, 1)\n",
    "    \n",
    "    def forward(self, hid, enc1=None):\n",
    "        for i in range(0,len(self.dec)-1):\n",
    "            hid = self.dec[i](hid)\n",
    "        Y = self.dec[-1](torch.cat([hid, enc1], dim=1))\n",
    "        Y = self.readout(Y)\n",
    "        return Y\n",
    "\n",
    "class Mid_Xnet(nn.Module):\n",
    "    def __init__(self, channel_in, channel_hid, N_T, incep_ker = [3,5,7,11], groups=8):\n",
    "        super(Mid_Xnet, self).__init__()\n",
    "\n",
    "        self.N_T = N_T\n",
    "        enc_layers = [Inception(channel_in, channel_hid//2, channel_hid, incep_ker= incep_ker, groups=groups)]\n",
    "        for i in range(1, N_T-1):\n",
    "            enc_layers.append(Inception(channel_hid, channel_hid//2, channel_hid, incep_ker= incep_ker, groups=groups))\n",
    "        enc_layers.append(Inception(channel_hid, channel_hid//2, channel_hid, incep_ker= incep_ker, groups=groups))\n",
    "\n",
    "        dec_layers = [Inception(channel_hid, channel_hid//2, channel_hid, incep_ker= incep_ker, groups=groups)]\n",
    "        for i in range(1, N_T-1):\n",
    "            dec_layers.append(Inception(2*channel_hid, channel_hid//2, channel_hid, incep_ker= incep_ker, groups=groups))\n",
    "        dec_layers.append(Inception(2*channel_hid, channel_hid//2, channel_in, incep_ker= incep_ker, groups=groups))\n",
    "\n",
    "        self.enc = nn.Sequential(*enc_layers)\n",
    "        self.dec = nn.Sequential(*dec_layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, C, D, H, W = x.shape\n",
    "        x = x.reshape(B, T*C, D, H, W)\n",
    "\n",
    "        # encoder\n",
    "        skips = []\n",
    "        z = x\n",
    "        for i in range(self.N_T):\n",
    "            z = self.enc[i](z)\n",
    "            if i < self.N_T - 1:\n",
    "                skips.append(z)\n",
    "\n",
    "        # decoder\n",
    "        z = self.dec[0](z)\n",
    "        for i in range(1, self.N_T):\n",
    "            z = self.dec[i](torch.cat([z, skips[-i]], dim=1))\n",
    "\n",
    "        y = z.reshape(B, T, C, D, H, W)\n",
    "        return y\n",
    "\n",
    "\n",
    "class SimVP(nn.Module):\n",
    "    def __init__(self, shape_in, hid_S=16, hid_T=256, N_S=4, N_T=8, incep_ker=[3,5,7,11], groups=8):\n",
    "        super(SimVP, self).__init__()\n",
    "        T, C, D, H, W = shape_in\n",
    "        self.enc = Encoder(C, hid_S, N_S)\n",
    "        self.hid = Mid_Xnet(T*hid_S, hid_T, N_T, incep_ker, groups)\n",
    "        self.dec = Decoder(hid_S, C, N_S)\n",
    "\n",
    "\n",
    "    def forward(self, x_raw):\n",
    "        B, T, C, D, H, W = x_raw.shape\n",
    "        x = x_raw.view(B*T, C, D, H, W)\n",
    "\n",
    "        embed, skip = self.enc(x)\n",
    "        _, C_, D_, H_, W_ = embed.shape\n",
    "\n",
    "        z = embed.view(B, T, C_, D_, H_, W_)\n",
    "        hid = self.hid(z)\n",
    "        hid = hid.reshape(B*T, C_, D_, H_, W_)\n",
    "\n",
    "        Y = self.dec(hid, skip)\n",
    "        Y = Y.reshape(B, T, C, D, H, W)\n",
    "        return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test model\n",
    "#model = SimVP(\n",
    "#    shape_in=[8, 1, 16, 256, 256]\n",
    "#).to(device)\n",
    "#inputs, targets = next(iter(train_loader))\n",
    "#print(inputs.shape)\n",
    "#out = model(inputs.to(device))\n",
    "#print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pl_Model(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        passed_model: nn.Module,\n",
    "        config: Dict[str, Any],\n",
    "    ):\n",
    "        super(Pl_Model, self).__init__()\n",
    "        self.passed_model = passed_model\n",
    "        self.config = config\n",
    "\n",
    "        #speicher alle parameter ab\n",
    "        self.save_hyperparameters(ignore=[\"passed_model\"])\n",
    "\n",
    "        \n",
    "        # Setup training components\n",
    "        self.mse_criterion = nn.MSELoss()\n",
    "        self.huber_criterion = nn.HuberLoss(delta=1.0)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.passed_model(x)\n",
    "        return x\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        \"\"\"Sets the Optimizer for the Model\"\"\"\n",
    "        optimizer = optim.Adam(\n",
    "            self.parameters(), \n",
    "            lr=config['learning_rate'],\n",
    "        )\n",
    "        return [optimizer]\n",
    "\n",
    "    def _calculate_loss(self, batch, mode=\"train\"):\n",
    "        \"\"\"Calculates the loss for a batch in different modes (training, validation, testing)\"\"\"\n",
    "        inputs, targets = batch\n",
    "        #to device\n",
    "        #inputs = inputs.to(device)\n",
    "        #targets = targets.to(device)\n",
    "        \n",
    "        \n",
    "\n",
    "        #forward pass\n",
    "        outputs = self.forward(inputs)\n",
    "        #get only the first predicted frame\n",
    "        outputs = outputs[:, :1, :, :, :, :]\n",
    "        #calcualte losses\n",
    "        mse_loss = self.mse_criterion(outputs, targets)\n",
    "        huber_loss = self.huber_criterion(outputs, targets)\n",
    "        total_loss = mse_loss + 0.5 * huber_loss\n",
    "\n",
    "        #logging\n",
    "        self.log(f\"{mode}_mse_loss\", mse_loss)\n",
    "        self.log(f\"{mode}_huber_loss\", huber_loss)\n",
    "        self.log(f\"{mode}_total_loss\", total_loss)\n",
    "\n",
    "        return total_loss, mse_loss, huber_loss\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss, _, _ = self._calculate_loss(batch, mode=\"train\")\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        _ = self._calculate_loss(batch, mode=\"val\")\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        _ = self._calculate_loss(batch, mode=\"test\")\n",
    "\n",
    "    def check_losses(self, loader, mode, use_wandb=False):\n",
    "        mse_loss = 0.0\n",
    "        huber_loss = 0.0\n",
    "        total_loss = 0.0\n",
    "        for inputs, targets in loader:\n",
    "            mse_loss_ = self.mse_criterion(inputs[:, -1, :, :, :, :].unsqueeze(1), targets)\n",
    "            huber_loss_ = self.huber_criterion(inputs[:, -1, :, :, :, :].unsqueeze(1), targets)\n",
    "            total_loss_ = mse_loss_ + 0.5 * huber_loss_   \n",
    "        \n",
    "            mse_loss += mse_loss_.item()\n",
    "            huber_loss += huber_loss_.item()\n",
    "            total_loss += total_loss_.item()\n",
    "        mse_loss = mse_loss/len(loader)\n",
    "        huber_loss = huber_loss/len(loader)\n",
    "        total_loss = total_loss/len(loader)\n",
    "    \n",
    "        if use_wandb:\n",
    "            self.log(f\"Checked_{mode}_mse_loss\", mse_loss)\n",
    "            self.log(f\"Checked_{mode}_mse_loss\", huber_loss)\n",
    "            self.log(f\"Checked_{mode}_mse_loss\", total_loss)\n",
    "        \n",
    "        return mse_loss, huber_loss, total_loss\n",
    "        \n",
    "    def log_predictions(self):\n",
    "        \"\"\"Log example predictions to wandb\"\"\"\n",
    "        #needs to be added to other method\n",
    "        if epoch % self.config['viz_interval'] == 0:\n",
    "                self.log_predictions()\n",
    "        #but this whole method needs to be rewritten\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            # Get a batch of validation data\n",
    "            data, target = next(iter(self.val_loader))\n",
    "            data = data.to(self.device)\n",
    "            target = target.to(self.device)\n",
    "            \n",
    "            # Generate predictions\n",
    "            output = self.model(data)\n",
    "            \n",
    "            # Log images\n",
    "            wandb.log({\n",
    "                \"predictions\": wandb.Image(output[0, 0].cpu()),\n",
    "                \"targets\": wandb.Image(target[0, 0].cpu()),\n",
    "                \"input_sequence\": [wandb.Image(data[0, i].cpu()) for i in range(data.shape[1])]\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n",
      "/usr/local/lib/python3.8/dist-packages/pytorch_lightning/core/module.py:445: You are trying to `self.log()` but the `self.trainer` reference is not registered on the model yet. This is most likely because the model hasn't been passed to the `Trainer`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.01140444865450263, 0.005697309458628297, 0.014253103360533714)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\n",
    "    #for the dataloaders\n",
    "    'batch_size': 1,\n",
    "    'learning_rate': 1e-4,\n",
    "    \"num_workers\": 4,#0, wenn die gpu nicht benutzt wird\n",
    "    \"pin_memory\": False,#False, wenn die gpu nicht benutzt wird\n",
    "    \"drop_last\": False,\n",
    "    'epochs': 30,\n",
    "    #'log_interval': 20,\n",
    "    #'viz_interval': 1,\n",
    "    'run_name': '3D-SimpVP_v1',\n",
    "    'input_frames': 8,\n",
    "    \"pred_frames\": 1,\n",
    "    'base_filters': 32\n",
    "}\n",
    "\n",
    "# Initialize model\n",
    "model = SimVP(\n",
    "    shape_in=[8, 1, 16, 256, 256]\n",
    ")\n",
    "\n",
    "# Get data loaders\n",
    "train_loader, val_loader, test_loader = get_data_loaders(\n",
    "    batch_size=config['batch_size'],\n",
    "    num_workers=config[\"num_workers\"],\n",
    "    pin_memory=config[\"pin_memory\"],\n",
    "    drop_last=config[\"drop_last\"],\n",
    "    sequence_length=config[\"input_frames\"], \n",
    "    prediction_length=config[\"pred_frames\"],\n",
    ")\n",
    "\n",
    "wandb_logger = WandbLogger(project=\"perfusion-ct-prediction\", name=config[\"run_name\"])\n",
    "\n",
    "# Initialize pl_model\n",
    "pl_model = Pl_Model(\n",
    "    passed_model=model,\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "# Initialize trainer\n",
    "trainer = pl.Trainer(\n",
    "    logger=wandb_logger,\n",
    "    accelerator=\"gpu\",\n",
    "    devices= [0] if torch.cuda.is_available() else None,\n",
    "    max_epochs=config[\"epochs\"],\n",
    ")\n",
    "\n",
    "wandb_logger.watch(pl_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "trainer.fit(\n",
    "    pl_model,\n",
    "    train_dataloaders=train_loader,\n",
    "    val_dataloaders=val_loader,\n",
    ")\n",
    "\n",
    "#check the losses \"to beat\"\n",
    "pl_model.check_losses(train_loader, mode=\"train\", use_wandb=True)\n",
    "pl_model.check_losses(val_loader, mode=\"val\", use_wandb=True)\n",
    "pl_model.check_losses(test_loader, mode=\"test\", use_wandb=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py:145: `.validate(ckpt_path=None)` was called without a model. The best model of the previous `fit` call will be used. You can pass `.validate(ckpt_path='best')` to use the best model or `.validate(ckpt_path='last')` to use the last model. If you pass a value, this warning will be silenced.\n",
      "Restoring states from the checkpoint path at ./perfusion-ct-prediction/fg4s8gxn/checkpoints/epoch=9-step=800.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at ./perfusion-ct-prediction/fg4s8gxn/checkpoints/epoch=9-step=800.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "589e0144285e413c802c61350e7f1446",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py:145: `.test(ckpt_path=None)` was called without a model. The best model of the previous `fit` call will be used. You can pass `.test(ckpt_path='best')` to use the best model or `.test(ckpt_path='last')` to use the last model. If you pass a value, this warning will be silenced.\n",
      "Restoring states from the checkpoint path at ./perfusion-ct-prediction/fg4s8gxn/checkpoints/epoch=9-step=800.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "     Validate metric           DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "     val_huber_loss        0.011393512599170208\n",
      "      val_mse_loss          0.02294391766190529\n",
      "     val_total_loss         0.02864067628979683\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at ./perfusion-ct-prediction/fg4s8gxn/checkpoints/epoch=9-step=800.ckpt\n",
      "/usr/local/lib/python3.8/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=255` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2891be38659416f83c06792d4919c26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |                                                                                                    …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "     test_huber_loss       0.009318809024989605\n",
      "      test_mse_loss         0.01876353845000267\n",
      "     test_total_loss        0.02342294156551361\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    }
   ],
   "source": [
    "val_results = trainer.validate(dataloaders=val_loader)\n",
    "test_results = trainer.test(dataloaders=test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_load_path = f\"../ModelWeights/{config['run_name']}.ckpt\"\n",
    "trainer.save_checkpoint(save_load_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, targets = next(iter(train_loader))\n",
    "inputs.shape, targets.shape\n",
    "pl_model=pl_model.to(device)\n",
    "outputs = pl_model(inputs.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 8, 1, 16, 256, 256]), torch.Size([1, 1, 1, 16, 256, 256]))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape, targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3831585ed82e4cccb04203f9a635dc3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='Time:', max=0), IntSlider(value=0, description='Slice:',…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "multi_vol_seq_interactive([outputs[0, :1, 0, :, :, :].detach().cpu().numpy(), targets[0, :, 0, :, :, :].cpu().numpy()])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ct",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
