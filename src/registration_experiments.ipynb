{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading /Users/simonma/Desktop/UniToBrain/MOL-106...\n",
      "Dicom files loaded, count: 288\n",
      "Processing /Users/simonma/Desktop/UniToBrain/MOL-106...\n",
      "5 [0.488281, 0.488281]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| volume_seq.max(): 160.0\n",
      "    volume_seq.min(): 0.0\n",
      "    volume_seq.dtype: dtype('float32')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time taken: 2.87 seconds\n",
      "Average time taken per volume: 0.16 seconds\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from preprocessing import load_folder_paths, load_dcm_datasets, get_volume\n",
    "from scipy import ndimage\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import SimpleITK as sitk\n",
    "import numpy as np\n",
    "\n",
    "paths = load_folder_paths()\n",
    "dataset_path = os.path.expanduser('~/Desktop/UniToBrain')\n",
    "path = os.path.join(dataset_path, 'MOL-106')\n",
    "v = get_volume(path, extract_brain=False, filter=True, window_params=(80, 160), correct_motion=False, standardize=False, spatial_downsampling_factor=2, temporal_downsampling_factor=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interactive Visualization Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact, IntSlider\n",
    "from math import ceil\n",
    "\n",
    "def overlay_volume_sequence_interactive(volume_seq):\n",
    "    num_overlays = len(volume_seq) - 1\n",
    "    nrows = ceil(num_overlays ** 0.5)\n",
    "    ncols = ceil(num_overlays / nrows)\n",
    "    print(f\"{nrows=} {ncols=}\")\n",
    "    def plot_slice(slice_idx):\n",
    "\n",
    "        fig, axes = plt.subplots(nrows, \n",
    "                                ncols, \n",
    "                                figsize=(5*ncols, 5*nrows),\n",
    "                                squeeze=True)\n",
    "        if nrows == 1:\n",
    "            if ncols == 1:\n",
    "                axes = [[axes]]\n",
    "            else:\n",
    "                axes = [axes]\n",
    "        print(f\"{axes=}\")\n",
    "        for i in range(num_overlays):\n",
    "            ax = axes[i // ncols][i % ncols]\n",
    "            print(f\"{ax=}\")\n",
    "            ax.imshow(volume_seq[0][slice_idx], cmap=\"gray\")\n",
    "            ax.imshow(volume_seq[i+1][slice_idx], cmap=\"hot\", alpha=0.5)\n",
    "        plt.show(block=True)\n",
    "    \n",
    "    interact(\n",
    "        plot_slice,\n",
    "        slice_idx=IntSlider(\n",
    "            min=0,\n",
    "            max=len(volume_seq[0])-1, \n",
    "            step=1,\n",
    "            value=0,\n",
    "            description='Slice:'\n",
    "        )\n",
    "    )\n",
    "\n",
    "def multi_vol_seq_interactive(volume_seqs, titles=None):\n",
    "    \"\"\"\n",
    "    Interactive plot of multiple volume sequences using ipywidgets\n",
    "    \n",
    "    Parameters:\n",
    "    - volume_seqs: List of 4D volume sequences to display\n",
    "    - titles: Optional list of titles for each sequence\n",
    "    \"\"\"\n",
    "    if titles is None:\n",
    "        titles = [f\"Volume {i+1}\" for i in range(len(volume_seqs))]\n",
    "        \n",
    "    num_volumes = len(volume_seqs)\n",
    "    nrows = int(num_volumes ** 0.5)\n",
    "    ncols = (num_volumes + nrows - 1) // nrows\n",
    "    \n",
    "    def plot_volumes(time_idx, slice_idx):\n",
    "        fig, axes = plt.subplots(nrows, ncols, \n",
    "                                figsize=(5*ncols, 5*nrows),\n",
    "                                squeeze=True)\n",
    "        if nrows == 1:\n",
    "            if ncols == 1:\n",
    "                axes = [[axes]]\n",
    "            else:\n",
    "                axes = [axes]\n",
    "                \n",
    "        for i, (volume_seq, title) in enumerate(zip(volume_seqs, titles)):\n",
    "            row, col = i // ncols, i % ncols\n",
    "            ax = axes[row][col]\n",
    "            \n",
    "            t = min(time_idx, len(volume_seq) - 1)\n",
    "            s = min(slice_idx, len(volume_seq[t]) - 1)\n",
    "            \n",
    "            im = ax.imshow(volume_seq[t][s], cmap='magma')\n",
    "            ax.set_title(title)\n",
    "            plt.colorbar(im, ax=ax)\n",
    "            \n",
    "        plt.tight_layout()\n",
    "        plt.show(block=True)\n",
    "        \n",
    "    max_time = max(len(vol) for vol in volume_seqs) - 1\n",
    "    max_slice = max(len(vol[0]) for vol in volume_seqs) - 1\n",
    "    \n",
    "    interact(\n",
    "        plot_volumes,\n",
    "        time_idx=IntSlider(min=0, max=max_time, step=1, value=0, description='Time:'),\n",
    "        slice_idx=IntSlider(min=0, max=max_slice, step=1, value=0, description='Slice:')\n",
    "    )\n",
    "\n",
    "def multi_vol_seq_interactive(volume_seqs, titles=None):\n",
    "    \"\"\"\n",
    "    Interactive plot of multiple volume sequences using ipywidgets\n",
    "    \n",
    "    Parameters:\n",
    "    - volume_seqs: List of 4D volume sequences to display\n",
    "    - titles: Optional list of titles for each sequence\n",
    "    \"\"\"\n",
    "    if titles is None:\n",
    "        titles = [f\"Volume {i+1}\" for i in range(len(volume_seqs))]\n",
    "        \n",
    "    num_volumes = len(volume_seqs)\n",
    "    nrows = int(num_volumes ** 0.5)\n",
    "    ncols = (num_volumes + nrows - 1) // nrows\n",
    "    \n",
    "    def plot_volumes(time_idx, slice_idx):\n",
    "        fig, axes = plt.subplots(nrows, ncols, \n",
    "                                figsize=(5*ncols, 5*nrows),\n",
    "                                squeeze=True)\n",
    "        if nrows == 1:\n",
    "            if ncols == 1:\n",
    "                axes = [[axes]]\n",
    "            else:\n",
    "                axes = [axes]\n",
    "                \n",
    "        for i, (volume_seq, title) in enumerate(zip(volume_seqs, titles)):\n",
    "            row, col = i // ncols, i % ncols\n",
    "            ax = axes[row][col]\n",
    "            \n",
    "            t = min(time_idx, len(volume_seq) - 1)\n",
    "            s = min(slice_idx, len(volume_seq[t]) - 1)\n",
    "            \n",
    "            im = ax.imshow(volume_seq[t][s], cmap='magma')\n",
    "            ax.set_title(title)\n",
    "            plt.colorbar(im, ax=ax)\n",
    "            \n",
    "            # Add format_coord function to display pixel values on hover\n",
    "            def make_format_coord(img):\n",
    "                def format_coord(x, y):\n",
    "                    if x is None or y is None:\n",
    "                        return \"\"\n",
    "                    x, y = int(x + 0.5), int(y + 0.5)\n",
    "                    if 0 <= y < img.shape[0] and 0 <= x < img.shape[1]:\n",
    "                        val = img[y, x]\n",
    "                        return f'x={x}, y={y}, value={val:.2f}'\n",
    "                    return 'x={:.0f}, y={:.0f}'.format(x, y)\n",
    "                return format_coord\n",
    "            \n",
    "            ax.format_coord = make_format_coord(volume_seq[t][s])\n",
    "            \n",
    "        plt.tight_layout()\n",
    "        plt.show(block=True)\n",
    "        \n",
    "    max_time = max(len(vol) for vol in volume_seqs) - 1\n",
    "    max_slice = max(len(vol[0]) for vol in volume_seqs) - 1\n",
    "    \n",
    "    interact(\n",
    "        plot_volumes,\n",
    "        time_idx=IntSlider(min=0, max=max_time, step=1, value=0, description='Time:'),\n",
    "        slice_idx=IntSlider(min=0, max=max_slice, step=1, value=0, description='Slice:')\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd2d61daa694405cbe3741be8a224c01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='Time:', max=17), IntSlider(value=0, description='Slice:'â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "multi_vol_seq_interactive([v])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "# Callback invoked when the StartEvent happens, sets up our new data.\n",
    "def start_plot():\n",
    "    global metric_values, multires_iterations\n",
    "\n",
    "    metric_values = []\n",
    "    multires_iterations = []\n",
    "\n",
    "\n",
    "# Callback invoked when the EndEvent happens, do cleanup of data and figure.\n",
    "def end_plot():\n",
    "    global metric_values, multires_iterations\n",
    "\n",
    "    del metric_values\n",
    "    del multires_iterations\n",
    "    # Close figure, we don't want to get a duplicate of the plot latter on.\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "# Callback invoked when the IterationEvent happens, update our data and display new figure.\n",
    "def plot_values(registration_method, metric_name='Metric Value'):\n",
    "    if registration_method.GetOptimizerIteration() % 10 == 0:\n",
    "        global metric_values, multires_iterations\n",
    "\n",
    "        metric_values.append(registration_method.GetMetricValue())\n",
    "        # Clear the output area (wait=True, to reduce flickering), and plot current data\n",
    "        clear_output(wait=True)\n",
    "        # Plot the similarity metric values\n",
    "        plt.plot(metric_values, \"r\")\n",
    "        plt.plot(\n",
    "            multires_iterations,\n",
    "            [metric_values[index] for index in multires_iterations],\n",
    "            \"b*\",\n",
    "        )\n",
    "        plt.xlabel(\"Iteration Number\", fontsize=12)\n",
    "        plt.ylabel(metric_name, fontsize=12)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "# Callback invoked when the sitkMultiResolutionIterationEvent happens, update the index into the\n",
    "# metric_values list.\n",
    "def update_multires_iterations():\n",
    "    global metric_values, multires_iterations\n",
    "    multires_iterations.append(len(metric_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_volume_slices(volume, title=None, cmap='magma'):\n",
    "    \"\"\"\n",
    "    Plots all slices of a 3D volume in a rectangular grid arrangement.\n",
    "    \n",
    "    Parameters:\n",
    "    - volume: 3D numpy array of shape (D, H, W)\n",
    "    - title: Optional string for overall figure title\n",
    "    - cmap: Colormap to use for plotting\n",
    "    \"\"\"\n",
    "    D = volume.shape[0]\n",
    "    vmin, vmax = np.min(volume), np.max(volume)\n",
    "\n",
    "    # Calculate grid dimensions to arrange plots in a roughly square layout\n",
    "    n_rows = int(np.ceil(np.sqrt(D)))\n",
    "    n_cols = int(np.ceil(D / n_rows))\n",
    "    \n",
    "    # Create figure and subplots\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 15))\n",
    "    if title:\n",
    "        fig.suptitle(title, fontsize=16)\n",
    "    \n",
    "    # Flatten axes array for easier iteration\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    # Plot each slice\n",
    "    for i in range(D):\n",
    "        axes[i].imshow(volume[i], cmap=cmap, vmin=vmin, vmax=vmax)\n",
    "        axes[i].axis('off')\n",
    "        axes[i].set_title(f'Slice {i}')\n",
    "    \n",
    "    # Turn off any empty subplots\n",
    "    for i in range(D, len(axes)):\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def register_volume_3D(moving_volume: np.ndarray, reference_volume: np.ndarray,\n",
    "               lr: float = 0.5, n_iters: int = 200, relaxation_factor: float = 0.9, \n",
    "               gradient_magnitude_tolerance: float = 1e-4, max_step: float = 4.0, min_step: float = 1e-4, \n",
    "               spacing: tuple = (0.488281, 0.488281, 5.0),\n",
    "               multi_res: bool = False):\n",
    "    \n",
    "    def command_iteration(method):\n",
    "        if (method.GetOptimizerIteration() + 1) % 50 == 0:\n",
    "            print(f\"Iteration: {method.GetOptimizerIteration()}\")\n",
    "            print(f\"Metric value: {method.GetMetricValue():.4f}\")\n",
    "\n",
    "    # Set min pixel value to 0 so that background aligns with pixels moved in by transformation during registration\n",
    "    # min_pixel_value = np.min(moving_volume)\n",
    "    # moving_volume, reference_volume = moving_volume - min_pixel_value, reference_volume - min_pixel_value\n",
    "\n",
    "    # Convert to SimpleITK images\n",
    "    moving = sitk.GetImageFromArray(moving_volume)\n",
    "    fixed = sitk.GetImageFromArray(reference_volume)\n",
    "    # if not multi_res:\n",
    "    #     moving_image = sitk.DiscreteGaussian(moving_image, smoothing_sigma)\n",
    "    #     reference_image = sitk.DiscreteGaussian(reference_image, smoothing_sigma)\n",
    "\n",
    "    moving.SetSpacing(spacing)\n",
    "    fixed.SetSpacing(spacing)\n",
    "    \n",
    "    print(\"moving size (x, y, z):\", moving.GetSize())\n",
    "    # Initialize 2D transform\n",
    "    # initial_transform = sitk.CenteredTransformInitializer(\n",
    "    #     fixed,\n",
    "    #     moving,\n",
    "    #     sitk.Euler3DTransform(),\n",
    "    #     sitk.CenteredTransformInitializerFilter.GEOMETRY\n",
    "    # )\n",
    "    # print(initial_transform)\n",
    "    # moving_array = sitk.GetArrayFromImage(moving)\n",
    "    # plot_volume_slices(moving_array, title=\"Moving Volume\")\n",
    "\n",
    "    # # Setup registration method\n",
    "    # reg_method = sitk.ImageRegistrationMethod()\n",
    "    # # registration_method.SetMetricAsMeanSquares()\n",
    "    # reg_method.SetMetricAsMattesMutualInformation(numberOfHistogramBins=100)\n",
    "    # reg_method.SetMetricSamplingPercentage(0.1)\n",
    "    # reg_method.SetMetricSamplingStrategy(sitk.ImageRegistrationMethod.RANDOM)\n",
    "    \n",
    "    # reg_method.SetInterpolator(sitk.sitkBSpline)\n",
    "    # reg_method.SetInitialTransform(initial_transform)\n",
    "\n",
    "    # # Optimizer settings\n",
    "    # reg_method.SetOptimizerAsRegularStepGradientDescent(\n",
    "    #     learningRate=lr,\n",
    "    #     maximumStepSizeInPhysicalUnits=max_step,\n",
    "    #     minStep=min_step,\n",
    "    #     numberOfIterations=n_iters,\n",
    "    #     gradientMagnitudeTolerance=gradient_magnitude_tolerance,\n",
    "    #     relaxationFactor=relaxation_factor,\n",
    "    # )\n",
    "\n",
    "    # reg_method.SetOptimizerScalesFromPhysicalShift()\n",
    "\n",
    "    # if multi_res:\n",
    "    #     reg_method.SetShrinkFactorsPerLevel(shrinkFactors=[2, 1])\n",
    "    #     reg_method.SetSmoothingSigmasPerLevel(smoothingSigmas=[1, 2])\n",
    "\n",
    "\n",
    "    # reg_method.AddCommand(sitk.sitkIterationEvent, lambda: command_iteration(reg_method))\n",
    "    # reg_method.AddCommand(sitk.sitkStartEvent, start_plot)\n",
    "    # reg_method.AddCommand(sitk.sitkEndEvent, end_plot)\n",
    "    # reg_method.AddCommand(sitk.sitkMultiResolutionIterationEvent, update_multires_iterations)\n",
    "    # reg_method.AddCommand(sitk.sitkIterationEvent, lambda: plot_values(reg_method, 'MSE'))\n",
    "\n",
    "\n",
    "    # final_transform = reg_method.Execute(fixed, moving)\n",
    "    # print(f\"Stopping condition: {reg_method.GetOptimizerStopConditionDescription()}\")\n",
    "\n",
    "    # resampled = sitk.Resample(\n",
    "    #     moving,\n",
    "    #     fixed,\n",
    "    #     final_transform,\n",
    "    #     sitk.sitkBSpline,  # B-spline interpolation for final resampling\n",
    "    #     0.0,               # Default value for out-of-range pixels\n",
    "    #     moving.GetPixelID()\n",
    "    # )\n",
    "    # return sitk.GetArrayFromImage(resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "moving size (x, y, z): (256, 256, 16)\n"
     ]
    }
   ],
   "source": [
    "v1 = register_volume_3D(v[1], v[0], lr=0.1, n_iters=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "306d144652d14944b980db4937df2699",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='Time:', max=1), IntSlider(value=0, description='Slice:',â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "multi_vol_seq_interactive([[v[0], v1], v[:2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "get_volume() got an unexpected keyword argument 'windowing'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m unwindowed \u001b[38;5;241m=\u001b[39m \u001b[43mget_volume\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpaths\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m13\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextract_brain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwindowing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcorrect_motion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspatial_downsampling_factor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemporal_downsampling_factor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: get_volume() got an unexpected keyword argument 'windowing'"
     ]
    }
   ],
   "source": [
    "unwindowed = get_volume(paths[13], extract_brain=False, windowing=False, correct_motion=False, spatial_downsampling_factor=2, temporal_downsampling_factor=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = unwindowed[1][0]\n",
    "# i = np.clip(i, -1024, 1000)\n",
    "i = (i > -40) & (i < 120)\n",
    "i = ndimage.binary_erosion(i, iterations=2)\n",
    "i = ndimage.binary_fill_holes(i)\n",
    "i = 1 - i\n",
    "print(np.mean(i))\n",
    "plt.imshow(i, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More of these ideas a few cells below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume_seq_2 = get_volume(paths[0], extract_brain=False, windowing=True, correct_motion=False, spatial_downsampling_factor=2, temporal_downsampling_factor=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlay_volume_sequence_interactive(volume_seq_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "ax[0].imshow(v1[0], cmap=\"gray\")\n",
    "ax[1].imshow(reg[0], cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume_seq_2 = get_volume(paths[130], extract_brain=False, windowing=True, correct_motion=False, spatial_downsampling_factor=2, temporal_downsampling_factor=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlay_volume_sequence_interactive(volume_seq_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = register_volume_inplane_weighted(volume_seq_2[0], volume_seq_2[1], n_samples=1, lr=1e-4, n_iters=500)\n",
    "overlay_volume_sequence_interactive([volume_seq_2[0], reg])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An registration framwork based on MSE\n",
    "- optimized registration parameters\n",
    "- added customizability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def register_2(moving_volume: np.ndarray, reference_volume: np.ndarray, n_samples: int = 5, \n",
    "               lr: float = 1.0, n_iters: int = 1000, relaxation_factor: float = 0.99, \n",
    "               gradient_magnitude_tolerance: float = 1e-5, max_step: float = 4.0, min_step: float = 5e-4, \n",
    "               weighting_scheme: str = 'inverse', spacing: tuple = (1, 1), plot_metrics: bool = True,\n",
    "               multi_res: bool = False, smoothing_sigma: float = 2.0,\n",
    "               verbose: bool = False):\n",
    "    Y, Z, X = moving_volume.shape\n",
    "    \n",
    "    middle = Y // 2\n",
    "    half_range = n_samples // 2\n",
    "    # Sample slice indices evenly   \n",
    "    slice_indices = np.linspace(middle - half_range, middle + half_range, n_samples, dtype=int)\n",
    "    \n",
    "    # Store transforms and their weights\n",
    "    transforms = []\n",
    "    metric_values = []\n",
    "\n",
    "    def command_iteration(method):\n",
    "        if (method.GetOptimizerIteration() + 1) % 50 == 0:\n",
    "            print(f\"Iteration: {method.GetOptimizerIteration()}\")\n",
    "            print(f\"Metric value: {method.GetMetricValue():.4f}\")\n",
    "\n",
    "    # Register each sampled slice\n",
    "    for slice_idx in slice_indices:\n",
    "        print(f\"Registering slice {slice_idx} of {Y}\")\n",
    "        # Get corresponding slices\n",
    "        moving_slice = moving_volume[slice_idx]\n",
    "        reference_slice = reference_volume[slice_idx]\n",
    "        # Set min pixel value to 0 so that background aligns with pixels moved in by transformation during registration\n",
    "        min_pixel_value = np.min(moving_slice)\n",
    "        moving_slice, reference_slice = moving_slice - min_pixel_value, reference_slice - min_pixel_value\n",
    "        if verbose:\n",
    "            print(f\"{min_pixel_value=}\")\n",
    "        # Convert to SimpleITK images\n",
    "        moving_image = sitk.GetImageFromArray(moving_slice)\n",
    "        reference_image = sitk.GetImageFromArray(reference_slice)\n",
    "        if not multi_res:\n",
    "            moving_image = sitk.DiscreteGaussian(moving_image, smoothing_sigma)\n",
    "            reference_image = sitk.DiscreteGaussian(reference_image, smoothing_sigma)\n",
    "        \n",
    "        # Set 2D spacing\n",
    "        moving_image.SetSpacing(spacing)\n",
    "        reference_image.SetSpacing(spacing)\n",
    "        \n",
    "        # Initialize 2D transform\n",
    "        initial_transform = sitk.CenteredTransformInitializer(\n",
    "            moving_image,\n",
    "            reference_image,\n",
    "            sitk.Euler2DTransform(),\n",
    "            sitk.CenteredTransformInitializerFilter.GEOMETRY\n",
    "        )\n",
    "        \n",
    "        # Setup registration method\n",
    "        registration_method = sitk.ImageRegistrationMethod()\n",
    "        registration_method.SetMetricAsMeanSquares()\n",
    "        \n",
    "\n",
    "        # Optimizer settings\n",
    "        registration_method.SetOptimizerAsRegularStepGradientDescent(\n",
    "            learningRate=lr,\n",
    "            maximumStepSizeInPhysicalUnits=max_step,\n",
    "            minStep=min_step,\n",
    "            numberOfIterations=n_iters,\n",
    "            gradientMagnitudeTolerance=gradient_magnitude_tolerance,\n",
    "            relaxationFactor=relaxation_factor,\n",
    "            \n",
    "        )\n",
    "        if multi_res:\n",
    "            registration_method.SetShrinkFactorsPerLevel(shrinkFactors=[2, 1])\n",
    "            registration_method.SetSmoothingSigmasPerLevel(smoothingSigmas=[1, 2])\n",
    "            registration_method.SmoothingSigmasAreSpecifiedInPhysicalUnitsOn()\n",
    "\n",
    "        registration_method.SetInitialTransform(initial_transform)\n",
    "        registration_method.SetInterpolator(sitk.sitkLinear)\n",
    "        if plot_metrics:\n",
    "            registration_method.AddCommand(sitk.sitkIterationEvent, lambda: command_iteration(registration_method))\n",
    "            registration_method.AddCommand(sitk.sitkStartEvent, start_plot)\n",
    "            registration_method.AddCommand(sitk.sitkEndEvent, end_plot)\n",
    "            registration_method.AddCommand(sitk.sitkMultiResolutionIterationEvent, update_multires_iterations)\n",
    "            registration_method.AddCommand(sitk.sitkIterationEvent, lambda: plot_values(registration_method, 'MSE'))\n",
    "        try:\n",
    "            final_transform = registration_method.Execute(reference_image, moving_image)\n",
    "            metric_value = registration_method.GetMetricValue()\n",
    "            print(slice_idx)\n",
    "            print(f\"Stopping condition: {registration_method.GetOptimizerStopConditionDescription()}\")\n",
    "            print(f\"Metric value: {metric_value:.4f}\")\n",
    "            # Store transform parameters and weight\n",
    "            params = final_transform.GetParameters()\n",
    "            center = final_transform.GetCenter()\n",
    "            transforms.append((params, center))\n",
    "            metric_values.append(metric_value)\n",
    "            \n",
    "        except RuntimeError as e:\n",
    "            print(f\"Registration failed for slice {slice_idx}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    if not transforms:\n",
    "        print(\"No successful registrations - returning original volume\")\n",
    "        return moving_volume\n",
    "    \n",
    "    # Convert metric values to weights based on chosen scheme\n",
    "    metric_values = np.array(metric_values)\n",
    "    print(metric_values)\n",
    "\n",
    "    if weighting_scheme == 'inverse':\n",
    "        # Original inverse weighting\n",
    "        weights = 1.0 / (metric_values + 1e-10)\n",
    "\n",
    "    elif weighting_scheme == 'inverse_root':\n",
    "        weights = 1.0 / (np.sqrt(metric_values) + 1e-10)\n",
    "    \n",
    "    elif weighting_scheme == 'exponential':\n",
    "        # Exponential decay: w = exp(-metric_value)\n",
    "        # More robust to outliers than inverse\n",
    "        weights = np.exp(-metric_values)\n",
    "    \n",
    "    elif weighting_scheme == 'softmax':\n",
    "        # Softmax-based weighting: emphasizes better matches while maintaining non-zero weights\n",
    "        # Negative because lower metric values are better\n",
    "        weights = np.exp(-metric_values) / np.sum(np.exp(-metric_values))\n",
    "        \n",
    "    elif weighting_scheme == 'rank':\n",
    "        # Rank-based weighting: less sensitive to absolute metric values\n",
    "        ranks = np.argsort(np.argsort(-metric_values))  # Higher rank for lower metric value\n",
    "        weights = 1.0 / (ranks + 1)\n",
    "    \n",
    "    elif weighting_scheme == 'threshold':\n",
    "        # Threshold-based: only keep transforms with metric values below mean\n",
    "        mean_metric = np.mean(metric_values)\n",
    "        weights = np.where(metric_values < mean_metric, 1.0, 0.0)\n",
    "        if np.sum(weights) == 0:  # If all transforms are above mean\n",
    "            weights = np.ones_like(metric_values)\n",
    "    \n",
    "    # Normalize weights\n",
    "    weights = weights / np.sum(weights)\n",
    "    \n",
    "    # Compute weighted average transformation\n",
    "    avg_angle = 0\n",
    "    avg_tx = 0\n",
    "    avg_ty = 0\n",
    "    avg_cx = 0\n",
    "    avg_cy = 0\n",
    "    \n",
    "    for (params, center), weight in zip(transforms, weights):\n",
    "        avg_angle += params[0] * weight\n",
    "        avg_tx += params[1] * weight\n",
    "        avg_ty += params[2] * weight\n",
    "        avg_cx += center[0] * weight\n",
    "        avg_cy += center[1] * weight\n",
    "    \n",
    "    print(f\"{avg_angle=:.4f} {avg_tx=:.4f} {avg_ty=:.4f} {avg_cx=:.4f} {avg_cy=:.4f}\")\n",
    "    # print(f\"Time taken: {time() - t1}\")\n",
    "        # Create final average transform\n",
    "    final_transform = sitk.Euler2DTransform()\n",
    "    final_transform.SetAngle(avg_angle)\n",
    "    final_transform.SetTranslation((avg_tx, avg_ty))\n",
    "    final_transform.SetCenter((avg_cx, avg_cy))\n",
    "    \n",
    "    # Apply transform to each slice of moving volume\n",
    "    registered_volume = np.zeros_like(moving_volume)\n",
    "    for i in range(moving_volume.shape[0]):\n",
    "        moving_slice = sitk.GetImageFromArray(moving_volume[i])\n",
    "        registered_slice = sitk.Resample(\n",
    "            moving_slice,\n",
    "            reference_image,\n",
    "            final_transform,\n",
    "            sitk.sitkLinear,\n",
    "            0.0, # min_pixel_value,\n",
    "            moving_slice.GetPixelID()\n",
    "        )\n",
    "        registered_volume[i] = sitk.GetArrayFromImage(registered_slice) + min_pixel_value\n",
    "\n",
    "    return registered_volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_2 = register_2(v2, v1, n_samples=1, lr=1, n_iters=500, weighting_scheme='inverse', plot_metrics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlay_volume_sequence_interactive([v1, reg_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_vol_seq_interactive([v, [v1, reg_2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "dataset_path = os.path.expanduser('~/Desktop/UniToBrain')\n",
    "path = os.path.join(dataset_path, 'MOL-112')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's try registration with different data:\n",
    "- less aggressive windowing\n",
    "- Skull-stripping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_raw = get_volume(paths[13], extract_brain=False, windowing=False, correct_motion=False, spatial_downsampling_factor=2, temporal_downsampling_factor=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing import get_3d_mask, apply_mask\n",
    "# v_raw[0] = apply_mask(v_raw[0], get_3d_mask(v_raw[0]))\n",
    "# v_raw[1] = apply_mask(v_raw[1], get_3d_mask(v_raw[1]))\n",
    "# v_raw = np.clip(v_raw, -200, 80)\n",
    "multi_vol_seq_interactive([v_raw, [v_raw[0], v_raw[1]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_raw = register_2(v_raw[1], v_raw[0], n_samples=1, lr=1, n_iters=200, relaxation_factor=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_vol_seq_interactive([v_raw, [v_raw[0], reg_raw]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "dataset_path = os.path.expanduser('~/Desktop/UniToBrain')\n",
    "path = os.path.join(dataset_path, 'MOL-133')\n",
    "v_133 = get_volume(path, extract_brain=False, windowing=True, correct_motion=False, spatial_downsampling_factor=2, temporal_downsampling_factor=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_133 = register_2(v_133[1], v_133[0], n_samples=1, lr=1, n_iters=200, weighting_scheme='inverse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_vol_seq_interactive([v_133, [v_133[0], reg_133]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This works! Notice the rotation correction from t=0 to t=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try this on the previous scan\n",
    "v_100_reg2 = register_2(v[1], v[0], n_samples=1, lr=1, n_iters=150, weighting_scheme='inverse')\n",
    "multi_vol_seq_interactive([v, [v[0], v_100_reg2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My goodness this works too, I've spent wayyy to much time on this simple registration task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_100_reg_multi_res = register_2(v[1], v[0], n_samples=1, lr=1, n_iters=1000, weighting_scheme='inverse', multi_res=True)\n",
    "multi_vol_seq_interactive([v, [v[0], v_100_reg_multi_res]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_100_reg1 = register_volume_inplane_weighted(v[1], v[0], n_samples=1, lr=1e-3, n_iters=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_106 = get_volume(os.path.join(dataset_path, 'MOL-106'), extract_brain=False, windowing=True, correct_motion=False, spatial_downsampling_factor=2, temporal_downsampling_factor=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlay_volume_sequence_interactive(v_106)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_106 = register_2(v_106[1], v_106[0], n_samples=1, lr=1.2, n_iters=1000, weighting_scheme='inverse', smoothing_sigma=5, )\n",
    "overlay_volume_sequence_interactive([v_106[0], reg_106])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_106_2 = reg_106 + np.min(v_106[0]) - np.min(reg_106)\n",
    "np.min(reg_106_2), np.min(v_106[0])\n",
    "# overlay_volume_sequence_interactive([v_106[0], reg_106_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_106 = register_2(v_106[0], v_106[1], n_samples=1, lr=0.11, n_iters=1000, weighting_scheme='inverse')\n",
    "multi_vol_seq_interactive([v_106, [reg_106, v_106[1]]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learning rate too low"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Without Windowing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_106_no_window = get_volume(os.path.join(dataset_path, 'MOL-106'), extract_brain=False, windowing=False, correct_motion=False, spatial_downsampling_factor=2, temporal_downsampling_factor=7)\n",
    "v_106_no_window = np.clip(v_106_no_window, -1024, 3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlay_volume_sequence_interactive(volum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_106_no_window = register_2(v_106_no_window[1], v_106_no_window[0], n_samples=1, lr=1, n_iters=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_vol_seq_interactive([v_106_no_window, [v_106_no_window[0],reg_106_no_window]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Noise Estimation\n",
    "- This part should help select a volume to act as the reference for registering other volumes in the sequence. It should be the least corrupted and least noisy out of the first few volumes of the sequence.\n",
    "- As we are doing in-plane registration, is suffices to only look at the images which are being sampled in registration and do noise estimation in 2D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def get_local_statistics(img, patch_size):\n",
    "    # Calculate local means and variances using sliding windows\n",
    "    kernel = np.ones((patch_size, patch_size)) / (patch_size * patch_size)\n",
    "    local_mean = ndimage.convolve(img, kernel, mode='reflect')\n",
    "    local_var = ndimage.convolve(img**2, kernel, mode='reflect') - local_mean**2\n",
    "    return local_mean, local_var\n",
    "\n",
    "def estimate_noise_levels(image, patch_size=16):\n",
    "    \"\"\"\n",
    "    Estimate quantum and electronic noise levels in a CT image.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    image : ndarray\n",
    "        2D array representing the CT image\n",
    "    patch_size : int\n",
    "        Size of patches for local variance estimation\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    quantum_noise : float\n",
    "        Estimated quantum noise level\n",
    "    electronic_noise : float\n",
    "        Estimated electronic noise level\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get local means and variances\n",
    "    means, variances = get_local_statistics(image, patch_size)\n",
    "    \n",
    "    # Flatten arrays for regression\n",
    "    means = means.flatten()\n",
    "    variances = variances.flatten()\n",
    "    \n",
    "    # Remove outliers and negative values\n",
    "    valid_indices = (variances > 0) & (means > 0)\n",
    "    means = means[valid_indices]\n",
    "    variances = variances[valid_indices]\n",
    "    \n",
    "    # Prepare data for linear regression\n",
    "    X = means.reshape(-1, 1)\n",
    "    y = variances\n",
    "    \n",
    "    # Fit linear model: variance = quantum_noise * mean + electronic_noise\n",
    "    model = LinearRegression()\n",
    "    model.fit(X, y)\n",
    "    \n",
    "    quantum_noise = model.coef_[0]  # Slope represents quantum noise\n",
    "    electronic_noise = model.intercept_  # Y-intercept represents electronic noise\n",
    "    \n",
    "    return quantum_noise, electronic_noise\n",
    "\n",
    "def validate_noise_estimation(image, patch_size=16, num_splits=5):\n",
    "    \"\"\"\n",
    "    Validate noise estimation by comparing results across image subsets.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    image : ndarray\n",
    "        2D array representing the CT image\n",
    "    patch_size : int\n",
    "        Size of patches for local variance estimation\n",
    "    num_splits : int\n",
    "        Number of random subsets to use for validation\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary containing mean and std of noise estimates\n",
    "    \"\"\"\n",
    "    quantum_estimates = []\n",
    "    electronic_estimates = []\n",
    "    \n",
    "    height, width = image.shape\n",
    "    for _ in range(num_splits):\n",
    "        # Create random mask for subset selection\n",
    "        mask = np.random.rand(height, width) > 0.5\n",
    "        subset = image.copy()\n",
    "        subset[~mask] = 0\n",
    "        \n",
    "        # Estimate noise for subset\n",
    "        q_noise, e_noise = estimate_noise_levels(subset, patch_size)\n",
    "        quantum_estimates.append(q_noise)\n",
    "        electronic_estimates.append(e_noise)\n",
    "    \n",
    "    return {\n",
    "        'quantum_noise_mean': np.mean(quantum_estimates),\n",
    "        'quantum_noise_std': np.std(quantum_estimates),\n",
    "        'electronic_noise_mean': np.mean(electronic_estimates),\n",
    "        'electronic_noise_std': np.std(electronic_estimates)\n",
    "    }\n",
    "\n",
    "def plot_noise_analysis(image, quantum_noise, electronic_noise):\n",
    "    \"\"\"\n",
    "    Create visualization of noise estimation results.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    image : ndarray\n",
    "        2D array representing the CT image\n",
    "    quantum_noise : float\n",
    "        Estimated quantum noise level\n",
    "    electronic_noise : float\n",
    "        Estimated electronic noise level\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    # Calculate local means and variances\n",
    "    means, variances = get_local_statistics(image, 16)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(means.flatten(), variances.flatten(), alpha=0.1, label='Local measurements')\n",
    "    \n",
    "    # Plot fitted line\n",
    "    x_range = np.linspace(means.min(), means.max(), 100)\n",
    "    y_fit = quantum_noise * x_range + electronic_noise\n",
    "    plt.plot(x_range, y_fit, 'r-', label='Fitted noise model')\n",
    "    \n",
    "    plt.xlabel('Local mean intensity')\n",
    "    plt.ylabel('Local variance')\n",
    "    plt.title('Noise Analysis Plot')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(estimate_noise_levels(v_106[0][0], patch_size=3))\n",
    "plt.imshow(v_106[0][0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing import bilateral_filter\n",
    "filtered = bilateral_filter(v_106[0][0], 10, 10)\n",
    "estimate_noise_levels(filtered, patch_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(filtered, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_noise_analysis(filtered, *estimate_noise_levels(filtered, patch_size=3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ct",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
